{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Treponema genome analysis workflow - Grillova et al. 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tested software versions and operation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The workflows has been tested on Linux machine (Ubuntu 16.04) with Python 2.7.6, Python 3.4.3 using Conda 4.5.11, Jupyter notebook 5.7.2 and bash_kernel 0.7.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uname -a\n",
    "lsb_release -a\n",
    "#export PATH=/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/bin:$PATH # In case we use different version of Conda than the system-wide installation\n",
    "which python3\n",
    "python3 --version\n",
    "which conda\n",
    "conda --version\n",
    "echo \"Jupyter notebook\" `jupyter notebook --version`\n",
    "echo \"bash_kernel\" `pip3 show bash_kernel | grep Version`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we can activate the environment and check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(treponema) (treponema) \n",
      "     active environment : treponema\n",
      "    active env location : /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema\n",
      "            shell level : 2\n",
      "       user config file : /mnt/nfs/home/325073/000000-My_Documents/VM-home/.condarc\n",
      " populated config files : /mnt/nfs/home/325073/000000-My_Documents/VM-home/.condarc\n",
      "          conda version : 4.6.14\n",
      "    conda-build version : not installed\n",
      "         python version : 2.7.16.final.0\n",
      "       base environment : /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2  (read only)\n",
      "           channel URLs : https://conda.anaconda.org/conda-forge/linux-64\n",
      "                          https://conda.anaconda.org/conda-forge/noarch\n",
      "                          https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/free/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/free/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://conda.anaconda.org/r/linux-64\n",
      "                          https://conda.anaconda.org/r/noarch\n",
      "                          https://conda.anaconda.org/bioconda/linux-64\n",
      "                          https://conda.anaconda.org/bioconda/noarch\n",
      "          package cache : /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/pkgs\n",
      "                          /mnt/nfs/home/325073/000000-My_Documents/VM-home/.conda/pkgs\n",
      "       envs directories : /mnt/nfs/home/325073/000000-My_Documents/VM-home/.conda/envs\n",
      "                          /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/4.6.14 requests/2.21.0 CPython/2.7.16 Linux/4.4.0-148-generic ubuntu/16.04.6 glibc/2.23\n",
      "                UID:GID : 100134:100006\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "(treponema) # packages in environment at /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_r-mutex                  1.0.0               anacondar_1  \n",
      "aragorn                   1.2.38               h470a237_2    bioconda\n",
      "asn1crypto                0.24.0                py27_1003    conda-forge\n",
      "atk                       2.32.0               haf93ef1_0    conda-forge\n",
      "augustus                  3.2.3               boost1.60_0    bioconda\n",
      "backports                 1.0                        py_2    conda-forge\n",
      "backports.functools_lru_cache 1.5                        py_1    conda-forge\n",
      "backports_abc             0.5                        py_1    conda-forge\n",
      "bamtools                  2.4.1                         1    bioconda\n",
      "barrnap                   0.8                           1    bioconda\n",
      "bbmap                     38.22                h14c3975_1    bioconda\n",
      "bcftools                  1.4.1                         0    bioconda\n",
      "besst                     2.2.8                      py_2    bioconda\n",
      "binutils_impl_linux-64    2.31.1               h6176602_1  \n",
      "binutils_linux-64         2.31.1               h6176602_7  \n",
      "bioconductor-biobase      2.42.0           r351h14c3975_1    bioconda\n",
      "bioconductor-biocgenerics 0.28.0                   r351_1    bioconda\n",
      "bioconductor-biocparallel 1.16.6           r351h1c2f66e_0    bioconda\n",
      "bioconductor-biostrings   2.50.2           r351h14c3975_0    bioconda\n",
      "bioconductor-delayedarray 0.8.0            r351h14c3975_0    bioconda\n",
      "bioconductor-genomeinfodb 1.18.1                   r351_0    bioconda\n",
      "bioconductor-genomeinfodbdata 1.2.1                    r351_0    bioconda\n",
      "bioconductor-genomicalignments 1.18.1           r351h14c3975_0    bioconda\n",
      "bioconductor-genomicranges 1.34.0           r351h14c3975_0    bioconda\n",
      "bioconductor-iranges      2.16.0           r351h14c3975_0    bioconda\n",
      "bioconductor-noiseq       2.26.1                   r351_0    bioconda\n",
      "bioconductor-rsamtools    1.34.0           r351hf484d3e_0    bioconda\n",
      "bioconductor-rtracklayer  1.42.1           r351h9d9f1b6_1    bioconda\n",
      "bioconductor-s4vectors    0.20.1           r351h14c3975_0    bioconda\n",
      "bioconductor-summarizedexperiment 1.12.0                   r351_0    bioconda\n",
      "bioconductor-xvector      0.22.0           r351h14c3975_0    bioconda\n",
      "bioconductor-zlibbioc     1.28.0           r351h14c3975_0    bioconda\n",
      "blas                      1.0                         mkl  \n",
      "blast                     2.9.0           pl526h979a64d_3    bioconda\n",
      "boost                     1.60.0                   py27_0  \n",
      "boost-cpp                 1.67.0               h3a22d5f_0    conda-forge\n",
      "busco                     3.0.2                    py27_8    bioconda\n",
      "bwa                       0.7.15                        1    bioconda\n",
      "bwidget                   1.9.11                        1  \n",
      "bz2file                   0.98                       py_0    conda-forge\n",
      "bzip2                     1.0.6             h14c3975_1002    conda-forge\n",
      "ca-certificates           2019.6.16            hecc5488_0    conda-forge\n",
      "cairo                     1.16.0            ha4e643d_1000    conda-forge\n",
      "certifi                   2019.6.16                py27_0    conda-forge\n",
      "cffi                      1.12.3           py27h8022711_0    conda-forge\n",
      "chardet                   3.0.4                 py27_1003    conda-forge\n",
      "chrpath                   0.16              h14c3975_1001    conda-forge\n",
      "circos                    0.69.6                        5    bioconda\n",
      "click                     7.0                        py_0    conda-forge\n",
      "clustalw                  2.1                  h6bb024c_4    bioconda\n",
      "colormath                 3.0.0                      py_2    conda-forge\n",
      "cryptography              2.7              py27h72c5cf5_0    conda-forge\n",
      "curl                      7.64.1               hf8cf82a_0    conda-forge\n",
      "cutadapt                  1.18             py27h14c3975_1    bioconda\n",
      "cycler                    0.10.0                     py_1    conda-forge\n",
      "dbus                      1.13.6               he372182_0    conda-forge\n",
      "decorator                 4.4.0                      py_0    conda-forge\n",
      "entrez-direct             11.0                    pl526_0    bioconda\n",
      "enum34                    1.1.6                 py27_1001    conda-forge\n",
      "expat                     2.2.5             hf484d3e_1002    conda-forge\n",
      "fastqc                    0.11.8                        1    bioconda\n",
      "font-ttf-dejavu-sans-mono 2.37                 h6964260_0  \n",
      "fontconfig                2.13.1            he4413a7_1000    conda-forge\n",
      "freebayes                 0.9.21.26                     0    bioconda\n",
      "freetype                  2.10.0               he983fc9_0    conda-forge\n",
      "functools32               3.2.3.2                    py_3    conda-forge\n",
      "future                    0.17.1                py27_1000    conda-forge\n",
      "futures                   3.2.0                 py27_1000    conda-forge\n",
      "gatk                      3.7                      py27_1    bioconda\n",
      "gcc_impl_linux-64         7.3.0                habb00fd_1    conda-forge\n",
      "gcc_linux-64              7.3.0                h553295d_7    conda-forge\n",
      "gdk-pixbuf                2.36.12           h7a26e22_1003    conda-forge\n",
      "gettext                   0.19.8.1          hc5be6a0_1002    conda-forge\n",
      "gfortran_impl_linux-64    7.3.0                hdf63c60_1  \n",
      "gfortran_linux-64         7.3.0                h553295d_7  \n",
      "giflib                    5.1.9                h516909a_0    conda-forge\n",
      "glib                      2.58.3            h6f030ca_1001    conda-forge\n",
      "glimmerhmm                3.0.4                h2d50403_2    bioconda\n",
      "gmp                       6.1.2             hf484d3e_1000    conda-forge\n",
      "gnuplot                   5.2.7                h213187a_0    conda-forge\n",
      "gnutls                    3.5.19               h2a4e5f8_1    conda-forge\n",
      "gobject-introspection     1.56.1          py27h2da5eee_1002    conda-forge\n",
      "graphite2                 1.3.13            hf484d3e_1000    conda-forge\n",
      "graphviz                  2.40.1               h0dab3d1_0    conda-forge\n",
      "gsl                       2.4                  h14c3975_4  \n",
      "gst-plugins-base          1.14.5               h0935bb2_0    conda-forge\n",
      "gstreamer                 1.14.5               h36ae1b5_0    conda-forge\n",
      "gtk2                      2.24.31           hb68c50a_1001    conda-forge\n",
      "gxx_impl_linux-64         7.3.0                hdf63c60_1    conda-forge\n",
      "gxx_linux-64              7.3.0                h553295d_7    conda-forge\n",
      "harfbuzz                  2.4.0                h37c48d4_1    conda-forge\n",
      "hmmer                     3.2.1                hf484d3e_1    bioconda\n",
      "htslib                    1.9                  h4da6232_3    bioconda\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\n",
      "idna                      2.8                   py27_1000    conda-forge\n",
      "infernal                  1.1.2                h14c3975_2    bioconda\n",
      "intel-openmp              2019.4                      243  \n",
      "ipaddress                 1.0.22                     py_1    conda-forge\n",
      "jinja2                    2.10.1                     py_0    conda-forge\n",
      "joblib                    0.13.2                     py_0    conda-forge\n",
      "jpeg                      9c                h14c3975_1001    conda-forge\n",
      "kiwisolver                1.1.0            py27hc9558a2_0    conda-forge\n",
      "kraken2                   2.0.8_beta      pl526h6bb024c_0    bioconda\n",
      "krb5                      1.16.3            h05b26f9_1001    conda-forge\n",
      "libcurl                   7.64.1               hda55be3_0    conda-forge\n",
      "libdb                     6.1.26                        0    bioconda\n",
      "libdeflate                1.2                  h14c3975_0    bioconda\n",
      "libedit                   3.1.20170329      hf8c457e_1001    conda-forge\n",
      "libffi                    3.2.1             he1b5a44_1006    conda-forge\n",
      "libgcc                    7.2.0                h69d50b8_2    conda-forge\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \n",
      "libgd                     2.2.5             h0d07dcb_1005    conda-forge\n",
      "libgfortran               3.0.0                         1    conda-forge\n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \n",
      "libiconv                  1.15              h516909a_1005    conda-forge\n",
      "libidn11                  1.34                 h1cef754_0    conda-forge\n",
      "libidn2                   2.1.1                h14c3975_0    conda-forge\n",
      "libpng                    1.6.37               hed695b0_0    conda-forge\n",
      "libssh2                   1.8.2                h22169c7_2    conda-forge\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \n",
      "libtiff                   4.0.10            h57b8799_1003    conda-forge\n",
      "libtool                   2.4.6             h14c3975_1002    conda-forge\n",
      "libunistring              0.9.10               h14c3975_0    conda-forge\n",
      "libuuid                   2.32.1            h14c3975_1000    conda-forge\n",
      "libwebp                   1.0.2                h576950b_1    conda-forge\n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\n",
      "libxml2                   2.9.9                h13577e0_0    conda-forge\n",
      "libxslt                   1.1.32            hae48121_1003    conda-forge\n",
      "lp_solve                  5.5.2.5           h14c3975_1001    conda-forge\n",
      "lz4-c                     1.8.3             he1b5a44_1001    conda-forge\n",
      "lzstring                  1.0.4                   py_1001    conda-forge\n",
      "make                      4.2.1             h14c3975_2004    conda-forge\n",
      "markdown                  2.6.11                     py_0    conda-forge\n",
      "markupsafe                1.1.1            py27h14c3975_0    conda-forge\n",
      "mathstats                 0.2.6.5                    py_0    bioconda\n",
      "matplotlib                2.2.3            py27hb69df0a_0  \n",
      "matplotlib-base           2.2.3            py27h60b886d_1    conda-forge\n",
      "metis                     5.1.0             hf484d3e_1003    conda-forge\n",
      "minced                    0.4.0                         0    bioconda\n",
      "mkl                       2019.4                      243  \n",
      "mkl_fft                   1.0.13           py27h516909a_1    conda-forge\n",
      "mkl_random                1.0.4            py27hf2d7682_0    conda-forge\n",
      "multiqc                   1.7                        py_4    bioconda\n",
      "mummer                    3.23                    pl526_8    bioconda\n",
      "ncurses                   6.1               hf484d3e_1002    conda-forge\n",
      "nettle                    3.3                           0    conda-forge\n",
      "networkx                  2.2                        py_1    conda-forge\n",
      "numpy                     1.16.4           py27h7e9f1db_0  \n",
      "numpy-base                1.16.4           py27hde5b4d6_0  \n",
      "openblas                  0.2.20                        8    conda-forge\n",
      "openjdk                   8.0.192           h14c3975_1003    conda-forge\n",
      "openssl                   1.1.1b               h14c3975_1    conda-forge\n",
      "paml                      4.9                  h14c3975_4    bioconda\n",
      "pango                     1.40.14           he7ab937_1005    conda-forge\n",
      "parallel                  20190522                      0    conda-forge\n",
      "pcre                      8.43                 he6710b0_0  \n",
      "perl                      5.26.2            h516909a_1006    conda-forge\n",
      "perl-aceperl              1.92                    pl526_2    bioconda\n",
      "perl-algorithm-diff       1.1903                  pl526_2    bioconda\n",
      "perl-algorithm-munkres    0.08                    pl526_1    bioconda\n",
      "perl-apache-test          1.40                    pl526_1    bioconda\n",
      "perl-app-cpanminus        1.7044                  pl526_1    bioconda\n",
      "perl-appconfig            1.71                    pl526_1    bioconda\n",
      "perl-archive-tar          2.32                    pl526_0    bioconda\n",
      "perl-array-compare        3.0.1                   pl526_1    bioconda\n",
      "perl-autoloader           5.74                    pl526_2    bioconda\n",
      "perl-base                 2.23                    pl526_1    bioconda\n",
      "perl-bio-asn1-entrezgene  1.73                    pl526_0    bioconda\n",
      "perl-bio-coordinate       1.007001                pl526_0    bioconda\n",
      "perl-bio-featureio        1.6.905                 pl526_1    bioconda\n",
      "perl-bio-phylo            0.58                    pl526_1    bioconda\n",
      "perl-bio-samtools         1.43            pl526h1341992_1    bioconda\n",
      "perl-bio-tools-phylo-paml 1.7.3                   pl526_0    bioconda\n",
      "perl-bio-tools-run-alignment-clustalw 1.7.4                   pl526_0    bioconda\n",
      "perl-bio-tools-run-alignment-tcoffee 1.7.4                   pl526_1    bioconda\n",
      "perl-bioperl              1.7.2                  pl526_10    bioconda\n",
      "perl-bioperl-core         1.007002                pl526_1    bioconda\n",
      "perl-bioperl-run          1.007002                pl526_3    bioconda\n",
      "perl-business-isbn        3.004                   pl526_0    bioconda\n",
      "perl-business-isbn-data   20140910.003            pl526_0    bioconda\n",
      "perl-cache-cache          1.08                    pl526_0    bioconda\n",
      "perl-capture-tiny         0.48                    pl526_0    bioconda\n",
      "perl-carp                 1.38                    pl526_3    bioconda\n",
      "perl-cgi                  4.44            pl526h14c3975_1    bioconda\n",
      "perl-class-data-inheritable 0.08                    pl526_1    bioconda\n",
      "perl-class-inspector      1.34                    pl526_0    bioconda\n",
      "perl-class-load           0.25                    pl526_0    bioconda\n",
      "perl-class-load-xs        0.10            pl526h6bb024c_2    bioconda\n",
      "perl-class-method-modifiers 2.12                    pl526_0    bioconda\n",
      "perl-clone                0.41            pl526h14c3975_1    bioconda\n",
      "perl-common-sense         3.74                    pl526_2    bioconda\n",
      "perl-compress-raw-bzip2   2.086           pl526hf484d3e_0    bioconda\n",
      "perl-compress-raw-zlib    2.086           pl526h6bb024c_1    bioconda\n",
      "perl-config-general       2.63                    pl526_0    bioconda\n",
      "perl-constant             1.33                    pl526_1    bioconda\n",
      "perl-convert-binary-c     0.78            pl526h6bb024c_3    bioconda\n",
      "perl-convert-binhex       1.125                   pl526_1    bioconda\n",
      "perl-cpan-meta            2.150010                pl526_0    bioconda\n",
      "perl-cpan-meta-requirements 2.140                   pl526_0    bioconda\n",
      "perl-cpan-meta-yaml       0.018                   pl526_0    bioconda\n",
      "perl-crypt-rc4            2.02                    pl526_1    bioconda\n",
      "perl-data-dumper          2.173                   pl526_0    bioconda\n",
      "perl-data-optlist         0.110                   pl526_2    bioconda\n",
      "perl-data-stag            0.14                    pl526_1    bioconda\n",
      "perl-date-format          2.30                    pl526_2    bioconda\n",
      "perl-db-file              1.852           pl526h14c3975_0    bioconda\n",
      "perl-dbd-sqlite           1.62            pl526h14c3975_1    bioconda\n",
      "perl-dbi                  1.642                   pl526_0    bioconda\n",
      "perl-devel-globaldestruction 0.14                    pl526_0    bioconda\n",
      "perl-devel-overloadinfo   0.005                   pl526_0    bioconda\n",
      "perl-devel-stacktrace     2.04                    pl526_0    bioconda\n",
      "perl-digest-hmac          1.03                    pl526_3    bioconda\n",
      "perl-digest-md5           2.55                    pl526_0    bioconda\n",
      "perl-digest-perl-md5      1.9                     pl526_1    bioconda\n",
      "perl-digest-sha1          2.13            pl526h6bb024c_1    bioconda\n",
      "perl-dist-checkconflicts  0.11                    pl526_2    bioconda\n",
      "perl-dynaloader           1.25                    pl526_1    bioconda\n",
      "perl-email-date-format    1.005                   pl526_2    bioconda\n",
      "perl-encode               2.88                    pl526_1    bioconda\n",
      "perl-encode-locale        1.05                    pl526_6    bioconda\n",
      "perl-error                0.17027                 pl526_1    bioconda\n",
      "perl-eval-closure         0.14            pl526h6bb024c_4    bioconda\n",
      "perl-exception-class      1.44                    pl526_0    bioconda\n",
      "perl-exporter             5.72                    pl526_1    bioconda\n",
      "perl-exporter-tiny        1.002001                pl526_0    bioconda\n",
      "perl-extutils-cbuilder    0.280230                pl526_1    bioconda\n",
      "perl-extutils-makemaker   7.36                    pl526_1    bioconda\n",
      "perl-extutils-manifest    1.72                    pl526_0    bioconda\n",
      "perl-extutils-parsexs     3.35                    pl526_0    bioconda\n",
      "perl-file-listing         6.04                    pl526_1    bioconda\n",
      "perl-file-path            2.16                    pl526_0    bioconda\n",
      "perl-file-slurp-tiny      0.004                   pl526_1    bioconda\n",
      "perl-file-sort            1.01                    pl526_2    bioconda\n",
      "perl-file-temp            0.2304                  pl526_2    bioconda\n",
      "perl-file-which           1.23                    pl526_0    bioconda\n",
      "perl-font-afm             1.20                    pl526_2    bioconda\n",
      "perl-font-ttf             1.06                    pl526_0    bioconda\n",
      "perl-gd                   2.71            pl526he860b03_0    bioconda\n",
      "perl-getopt-long          2.50                    pl526_1    bioconda\n",
      "perl-graph                0.9704                  pl526_1    bioconda\n",
      "perl-graphviz             2.24            pl526h734ff71_0    bioconda\n",
      "perl-html-element-extended 1.18                    pl526_1    bioconda\n",
      "perl-html-entities-numbered 0.04                    pl526_1    bioconda\n",
      "perl-html-formatter       2.16                    pl526_0    bioconda\n",
      "perl-html-parser          3.72            pl526h6bb024c_5    bioconda\n",
      "perl-html-tableextract    2.13                    pl526_2    bioconda\n",
      "perl-html-tagset          3.20                    pl526_3    bioconda\n",
      "perl-html-tidy            1.60                    pl526_0    bioconda\n",
      "perl-html-tree            5.07                    pl526_1    bioconda\n",
      "perl-html-treebuilder-xpath 0.14                    pl526_1    bioconda\n",
      "perl-http-cookies         6.04                    pl526_0    bioconda\n",
      "perl-http-daemon          6.01                    pl526_1    bioconda\n",
      "perl-http-date            6.02                    pl526_3    bioconda\n",
      "perl-http-message         6.18                    pl526_0    bioconda\n",
      "perl-http-negotiate       6.01                    pl526_3    bioconda\n",
      "perl-image-info           1.38                    pl526_1    bioconda\n",
      "perl-image-size           3.300                   pl526_2    bioconda\n",
      "perl-io-compress          2.086           pl526hf484d3e_0    bioconda\n",
      "perl-io-html              1.001                   pl526_2    bioconda\n",
      "perl-io-sessiondata       1.03                    pl526_1    bioconda\n",
      "perl-io-socket-ssl        2.066                   pl526_0    bioconda\n",
      "perl-io-string            1.08                    pl526_3    bioconda\n",
      "perl-io-stringy           2.111                   pl526_1    bioconda\n",
      "perl-io-tty               1.12                    pl526_1    bioconda\n",
      "perl-io-zlib              1.10                    pl526_2    bioconda\n",
      "perl-ipc-cmd              1.02                    pl526_0    bioconda\n",
      "perl-ipc-run              20180523.0              pl526_0    bioconda\n",
      "perl-ipc-sharelite        0.17            pl526h6bb024c_1    bioconda\n",
      "perl-jcode                2.07                    pl526_2    bioconda\n",
      "perl-json                 4.02                    pl526_0    bioconda\n",
      "perl-json-pp              4.02                    pl526_0    bioconda\n",
      "perl-json-xs              2.34            pl526h6bb024c_3    bioconda\n",
      "perl-lib                  0.63                    pl526_1    bioconda\n",
      "perl-libwww-perl          6.39                    pl526_0    bioconda\n",
      "perl-libxml-perl          0.08                    pl526_2    bioconda\n",
      "perl-list-moreutils       0.428                   pl526_1    bioconda\n",
      "perl-list-moreutils-xs    0.428                   pl526_0    bioconda\n",
      "perl-locale-maketext-simple 0.21                    pl526_2    bioconda\n",
      "perl-lwp-mediatypes       6.04                    pl526_0    bioconda\n",
      "perl-lwp-protocol-https   6.07                    pl526_4    bioconda\n",
      "perl-lwp-simple           6.15            pl526h470a237_4    bioconda\n",
      "perl-mailtools            2.21                    pl526_0    bioconda\n",
      "perl-math-bezier          0.01                    pl526_1    bioconda\n",
      "perl-math-cdf             0.1             pl526h14c3975_5    bioconda\n",
      "perl-math-derivative      1.01                    pl526_0    bioconda\n",
      "perl-math-random          0.72            pl526h14c3975_2    bioconda\n",
      "perl-math-round           0.07                    pl526_1    bioconda\n",
      "perl-math-spline          0.02                    pl526_2    bioconda\n",
      "perl-math-vecstat         0.08                    pl526_1    bioconda\n",
      "perl-mime-base64          3.15                    pl526_1    bioconda\n",
      "perl-mime-lite            3.030                   pl526_1    bioconda\n",
      "perl-mime-tools           5.508                   pl526_1    bioconda\n",
      "perl-mime-types           2.17                    pl526_0    bioconda\n",
      "perl-mldbm                2.05                    pl526_1    bioconda\n",
      "perl-module-build         0.4224                  pl526_3    bioconda\n",
      "perl-module-corelist      5.20190524              pl526_0    bioconda\n",
      "perl-module-implementation 0.09                    pl526_2    bioconda\n",
      "perl-module-load          0.32                    pl526_1    bioconda\n",
      "perl-module-load-conditional 0.68                    pl526_2    bioconda\n",
      "perl-module-metadata      1.000036                pl526_0    bioconda\n",
      "perl-module-runtime       0.016                   pl526_1    bioconda\n",
      "perl-module-runtime-conflicts 0.003                   pl526_0    bioconda\n",
      "perl-moo                  2.003004                pl526_0    bioconda\n",
      "perl-moose                2.2011          pl526hf484d3e_1    bioconda\n",
      "perl-mozilla-ca           20180117                pl526_1    bioconda\n",
      "perl-mro-compat           0.13                    pl526_0    bioconda\n",
      "perl-net-http             6.19                    pl526_0    bioconda\n",
      "perl-net-ssleay           1.88            pl526h90d6eec_0    bioconda\n",
      "perl-ntlm                 1.09                    pl526_4    bioconda\n",
      "perl-number-format        1.75                    pl526_3    bioconda\n",
      "perl-ole-storage_lite     0.19                    pl526_3    bioconda\n",
      "perl-package-deprecationmanager 0.17                    pl526_0    bioconda\n",
      "perl-package-stash        0.38            pl526hf484d3e_1    bioconda\n",
      "perl-package-stash-xs     0.28            pl526hf484d3e_1    bioconda\n",
      "perl-params-check         0.38                    pl526_1    bioconda\n",
      "perl-params-util          1.07            pl526h6bb024c_4    bioconda\n",
      "perl-params-validate      1.29            pl526h14c3975_1    bioconda\n",
      "perl-parent               0.236                   pl526_1    bioconda\n",
      "perl-parse-recdescent     1.967015                pl526_0    bioconda\n",
      "perl-pathtools            3.75            pl526h14c3975_1    bioconda\n",
      "perl-pdf-api2             2.033                   pl526_0    bioconda\n",
      "perl-perl-ostype          1.010                   pl526_1    bioconda\n",
      "perl-pod-escapes          1.07                    pl526_1    bioconda\n",
      "perl-pod-usage            1.69                    pl526_1    bioconda\n",
      "perl-postscript           0.06                    pl526_2    bioconda\n",
      "perl-readonly             2.05                    pl526_0    bioconda\n",
      "perl-regexp-common        2017060201              pl526_0    bioconda\n",
      "perl-role-tiny            2.000006                pl526_0    bioconda\n",
      "perl-scalar-list-utils    1.50            pl526h14c3975_0    bioconda\n",
      "perl-set-intspan          1.19                    pl526_1    bioconda\n",
      "perl-set-scalar           1.29                    pl526_2    bioconda\n",
      "perl-soap-lite            1.19                    pl526_1    bioconda\n",
      "perl-socket               2.027                   pl526_1    bioconda\n",
      "perl-sort-naturally       1.03                    pl526_2    bioconda\n",
      "perl-spreadsheet-parseexcel 0.65                    pl526_2    bioconda\n",
      "perl-spreadsheet-writeexcel 2.40                    pl526_2    bioconda\n",
      "perl-statistics-basic     1.6611                  pl526_2    bioconda\n",
      "perl-statistics-descriptive 3.0702                  pl526_0    bioconda\n",
      "perl-storable             3.15            pl526h14c3975_0    bioconda\n",
      "perl-sub-exporter         0.987                   pl526_2    bioconda\n",
      "perl-sub-exporter-progressive 0.001013                pl526_0    bioconda\n",
      "perl-sub-identify         0.14            pl526h14c3975_0    bioconda\n",
      "perl-sub-install          0.928                   pl526_2    bioconda\n",
      "perl-sub-name             0.21                    pl526_1    bioconda\n",
      "perl-sub-quote            2.006003                pl526_1    bioconda\n",
      "perl-sub-uplevel          0.2800          pl526h14c3975_2    bioconda\n",
      "perl-svg                  2.84                    pl526_0    bioconda\n",
      "perl-svg-graph            0.02                    pl526_3    bioconda\n",
      "perl-task-weaken          1.06                    pl526_0    bioconda\n",
      "perl-template-toolkit     2.26                    pl526_1    bioconda\n",
      "perl-test                 1.26                    pl526_1    bioconda\n",
      "perl-test-deep            1.128                   pl526_1    bioconda\n",
      "perl-test-differences     0.67                    pl526_0    bioconda\n",
      "perl-test-exception       0.43                    pl526_2    bioconda\n",
      "perl-test-harness         3.42                    pl526_0    bioconda\n",
      "perl-test-leaktrace       0.16            pl526h14c3975_2    bioconda\n",
      "perl-test-most            0.35                    pl526_0    bioconda\n",
      "perl-test-requiresinternet 0.05                    pl526_0    bioconda\n",
      "perl-test-warn            0.36                    pl526_1    bioconda\n",
      "perl-text-abbrev          1.02                    pl526_0    bioconda\n",
      "perl-text-diff            1.45                    pl526_0    bioconda\n",
      "perl-text-format          0.59                    pl526_2    bioconda\n",
      "perl-text-parsewords      3.30                    pl526_0    bioconda\n",
      "perl-tie-ixhash           1.23                    pl526_2    bioconda\n",
      "perl-time-hires           1.9760          pl526h14c3975_1    bioconda\n",
      "perl-time-local           1.28                    pl526_1    bioconda\n",
      "perl-timedate             2.30                    pl526_1    bioconda\n",
      "perl-tree-dag_node        1.31                    pl526_0    bioconda\n",
      "perl-try-tiny             0.30                    pl526_1    bioconda\n",
      "perl-type-tiny            1.004004                pl526_0    bioconda\n",
      "perl-types-serialiser     1.0                     pl526_2    bioconda\n",
      "perl-unicode-map          0.112           pl526h6bb024c_3    bioconda\n",
      "perl-uri                  1.76                    pl526_0    bioconda\n",
      "perl-vcftools-vcf         0.1.15                  pl526_2    bioconda\n",
      "perl-version              0.9924                  pl526_0    bioconda\n",
      "perl-www-robotrules       6.02                    pl526_3    bioconda\n",
      "perl-xml-dom              1.46                    pl526_0    bioconda\n",
      "perl-xml-dom-xpath        0.14                    pl526_1    bioconda\n",
      "perl-xml-filter-buffertext 1.01                    pl526_2    bioconda\n",
      "perl-xml-libxml           2.0132          pl526hbc14f71_0    bioconda\n",
      "perl-xml-libxslt          1.94                    pl526_1    bioconda\n",
      "perl-xml-namespacesupport 1.12                    pl526_0    bioconda\n",
      "perl-xml-parser           2.44            pl526h4e0c4b3_7    bioconda\n",
      "perl-xml-regexp           0.04                    pl526_2    bioconda\n",
      "perl-xml-sax              1.02                    pl526_0    bioconda\n",
      "perl-xml-sax-base         1.09                    pl526_0    bioconda\n",
      "perl-xml-sax-expat        0.51                    pl526_3    bioconda\n",
      "perl-xml-sax-writer       0.57                    pl526_0    bioconda\n",
      "perl-xml-simple           2.25                    pl526_1    bioconda\n",
      "perl-xml-twig             3.52                    pl526_2    bioconda\n",
      "perl-xml-writer           0.625                   pl526_2    bioconda\n",
      "perl-xml-xpath            1.44                    pl526_0    bioconda\n",
      "perl-xml-xpathengine      0.14                    pl526_2    bioconda\n",
      "perl-xsloader             0.24                    pl526_0    bioconda\n",
      "perl-yaml                 1.29                    pl526_0    bioconda\n",
      "picard                    2.9.2                         2    bioconda\n",
      "pigz                      2.3.4                         0    conda-forge\n",
      "pip                       19.1.1                   py27_0    conda-forge\n",
      "pixman                    0.34.0            h14c3975_1003    conda-forge\n",
      "popt                      1.16                          1    bioconda\n",
      "prodigal                  2.6.3                         1    bioconda\n",
      "prokka                    1.13.7                  pl526_0    bioconda\n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\n",
      "pycparser                 2.19                     py27_1    conda-forge\n",
      "pyopenssl                 19.0.0                   py27_0    conda-forge\n",
      "pyparsing                 2.4.0                      py_0    conda-forge\n",
      "pyqt                      5.9.2            py27hcca6a23_0    conda-forge\n",
      "pysam                     0.11.2.2                 py27_1    bioconda\n",
      "pysocks                   1.7.0                    py27_0    conda-forge\n",
      "python                    2.7.15            h721da81_1008    conda-forge\n",
      "python-dateutil           2.8.0                      py_0    conda-forge\n",
      "pytz                      2019.1                     py_0    conda-forge\n",
      "pyyaml                    5.1.1            py27h516909a_0    conda-forge\n",
      "qt                        5.9.7                h52cfd70_2    conda-forge\n",
      "qualimap                  2.2.2b                        1    bioconda\n",
      "quast                     5.0.2           py27pl526ha92aebf_0    bioconda\n",
      "r                         3.5.1                 r351_1000    conda-forge\n",
      "r-assertthat              0.2.1            r351h6115d3f_0    conda-forge\n",
      "r-backports               1.1.4            r351hcdcec82_0    conda-forge\n",
      "r-base                    3.5.1             h271c98b_1006    conda-forge\n",
      "r-bh                      1.69.0_1         r351h6115d3f_0    conda-forge\n",
      "r-bitops                  1.0_6           r351h96ca727_1002    conda-forge\n",
      "r-boot                    1.3_22                   r351_0    conda-forge\n",
      "r-class                   7.3_15          r351h96ca727_1000    conda-forge\n",
      "r-cli                     1.1.0            r351h6115d3f_0    conda-forge\n",
      "r-cluster                 2.0.9            r351h9bbef5b_0    conda-forge\n",
      "r-codetools               0.2_16          r351h6115d3f_1000    conda-forge\n",
      "r-colorspace              1.4_1            r351hcdcec82_0    conda-forge\n",
      "r-crayon                  1.3.4           r351h6115d3f_1001    conda-forge\n",
      "r-digest                  0.6.19           r351h0357c0b_0    conda-forge\n",
      "r-fansi                   0.4.0           r351h96ca727_1000    conda-forge\n",
      "r-foreign                 0.8_71          r351h96ca727_1002    conda-forge\n",
      "r-formatr                 1.7               r35h6115d3f_0    conda-forge\n",
      "r-futile.logger           1.4.3           r351h6115d3f_1001    conda-forge\n",
      "r-futile.options          1.0.1           r351h6115d3f_1000    conda-forge\n",
      "r-getopt                  1.20.3                   r351_0    conda-forge\n",
      "r-ggplot2                 3.2.0             r35h6115d3f_0    conda-forge\n",
      "r-glue                    1.3.1            r351hcdcec82_0    conda-forge\n",
      "r-gtable                  0.3.0            r351h6115d3f_0    conda-forge\n",
      "r-kernsmooth              2.23_15         r351ha65eedd_1002    conda-forge\n",
      "r-labeling                0.3             r351h6115d3f_1001    conda-forge\n",
      "r-lambda.r                1.2.3           r351h6115d3f_1000    conda-forge\n",
      "r-lattice                 0.20_38         r351h96ca727_1000    conda-forge\n",
      "r-lazyeval                0.2.2            r351hcdcec82_0    conda-forge\n",
      "r-magrittr                1.5             r351h6115d3f_1001    conda-forge\n",
      "r-mass                    7.3_51.4         r351hcdcec82_0    conda-forge\n",
      "r-matrix                  1.2_17           r351hcdcec82_0    conda-forge\n",
      "r-matrixstats             0.54.0          r351h96ca727_1000    conda-forge\n",
      "r-mgcv                    1.8_28           r351hcdcec82_0    conda-forge\n",
      "r-munsell                 0.5.0           r351h6115d3f_1001    conda-forge\n",
      "r-nlme                    3.1_140          r351h9bbef5b_0    conda-forge\n",
      "r-nnet                    7.3_12          r351h96ca727_1002    conda-forge\n",
      "r-optparse                1.6.1            r351h6115d3f_0    conda-forge\n",
      "r-pillar                  1.4.1                h6115d3f_0    conda-forge\n",
      "r-pkgconfig               2.0.2           r351h6115d3f_1001    conda-forge\n",
      "r-plyr                    1.8.4           r351h29659fb_1002    conda-forge\n",
      "r-r6                      2.4.0            r351h6115d3f_0    conda-forge\n",
      "r-rcolorbrewer            1.1_2           r351h6115d3f_1001    conda-forge\n",
      "r-rcpp                    1.0.1            r351h0357c0b_0    conda-forge\n",
      "r-rcurl                   1.95_4.12        r351hcdcec82_0    conda-forge\n",
      "r-recommended             3.5.1                 r351_1001    conda-forge\n",
      "r-reshape2                1.4.3           r351h29659fb_1003    conda-forge\n",
      "r-rlang                   0.3.4            r351hcdcec82_0    conda-forge\n",
      "r-rpart                   4.1_15           r351hcdcec82_0    conda-forge\n",
      "r-scales                  1.0.0           r351h29659fb_1001    conda-forge\n",
      "r-snow                    0.4_3           r351h6115d3f_1000    conda-forge\n",
      "r-spatial                 7.3_11          r351h96ca727_1002    conda-forge\n",
      "r-stringi                 1.4.3            r351h0357c0b_0    conda-forge\n",
      "r-stringr                 1.4.0            r351h6115d3f_0    conda-forge\n",
      "r-survival                2.44_1.1         r351hcdcec82_0    conda-forge\n",
      "r-tibble                  2.1.3             r35hcdcec82_0    conda-forge\n",
      "r-utf8                    1.1.4           r351h96ca727_1000    conda-forge\n",
      "r-vctrs                   0.1.0           r351h96ca727_1000    conda-forge\n",
      "r-viridislite             0.3.0           r351h6115d3f_1001    conda-forge\n",
      "r-withr                   2.1.2           r351h6115d3f_1000    conda-forge\n",
      "r-xml                     3.98_1.20         r35hcdcec82_0    conda-forge\n",
      "r-zeallot                 0.1.0           r351h6115d3f_1000    conda-forge\n",
      "readline                  7.0               hf8c457e_1001    conda-forge\n",
      "reaper                    16.098               ha92aebf_2    bioconda\n",
      "requests                  2.22.0                   py27_0    conda-forge\n",
      "rsync                     3.1.3             h84994c4_1002    conda-forge\n",
      "samtools                  1.4.1                         0    bioconda\n",
      "scipy                     1.2.1            py27h7c811a0_0  \n",
      "seqtk                     1.3                  h84994c4_1    bioconda\n",
      "setuptools                41.0.1                   py27_0    conda-forge\n",
      "simplejson                3.8.1                    py27_0    bioconda\n",
      "singledispatch            3.4.0.3               py27_1000    conda-forge\n",
      "sip                       4.19.8          py27hf484d3e_1000    conda-forge\n",
      "six                       1.12.0                py27_1000    conda-forge\n",
      "snpeff                    4.3.1t                        2    bioconda\n",
      "spades                    3.13.0                        0    bioconda\n",
      "spectra                   0.0.11                     py_1    conda-forge\n",
      "sqlite                    3.28.0               h8b20d00_0    conda-forge\n",
      "subprocess32              3.5.4            py27h516909a_0    conda-forge\n",
      "suitesparse               5.2.0                h9e4a6bb_0  \n",
      "t_coffee                  11.0.8           py27hea885bf_8    bioconda\n",
      "tbb                       2019.7               hc9558a2_0    conda-forge\n",
      "tbl2asn                   25.6                          3    bioconda\n",
      "tidyp                     1.04                          1    bioconda\n",
      "tk                        8.6.9             hed695b0_1002    conda-forge\n",
      "tktable                   2.10                 h14c3975_0  \n",
      "tornado                   5.1.1           py27h14c3975_1000    conda-forge\n",
      "urllib3                   1.24.3                   py27_0    conda-forge\n",
      "vcflib                    1.0.0_rc2            h56106d0_2    bioconda\n",
      "vcftools                  0.1.15               he941832_2    bioconda\n",
      "virtualenv                16.0.0                   py27_0    anaconda\n",
      "wget                      1.20.1               h90d6eec_0    conda-forge\n",
      "wheel                     0.33.4                   py27_0    conda-forge\n",
      "xopen                     0.7.0                      py_0    bioconda\n",
      "xorg-kbproto              1.0.7             h14c3975_1002    conda-forge\n",
      "xorg-libice               1.0.9             h516909a_1004    conda-forge\n",
      "xorg-libsm                1.2.3             h84519dc_1000    conda-forge\n",
      "xorg-libx11               1.6.7             h14c3975_1000    conda-forge\n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\n",
      "xorg-libxext              1.3.4                h516909a_0    conda-forge\n",
      "xorg-libxpm               3.5.12            h14c3975_1002    conda-forge\n",
      "xorg-libxrender           0.9.10            h516909a_1002    conda-forge\n",
      "xorg-libxt                1.1.5             h516909a_1003    conda-forge\n",
      "xorg-renderproto          0.11.1            h14c3975_1002    conda-forge\n",
      "xorg-xextproto            7.3.0             h14c3975_1002    conda-forge\n",
      "xorg-xproto               7.0.31            h14c3975_1007    conda-forge\n",
      "xz                        5.2.4             h14c3975_1001    conda-forge\n",
      "yaml                      0.1.7             h14c3975_1001    conda-forge\n",
      "zlib                      1.2.11            h14c3975_1004    conda-forge\n",
      "zstd                      1.4.0                h3b9ef0a_0    conda-forge\n",
      "(treponema) (treponema) (treponema) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "conda activate treponema\n",
    "# In case we want to export the system settings and software versions\n",
    "conda info\n",
    "conda list\n",
    "# In case we modified the environment want to export it\n",
    "#conda env export > treponema_mod.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we have to setup few variables which will be used throughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR=\"/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/data/raw\" # Directory with the raw paired input files in fastq.gz - first pair has to be named xxx_R1.fastq.gz and the second xxx_R2.fastq.gz otherwise you would have to change the input suffixes for the individual steps\n",
    "OUTPUT_DIR=\"/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/results\" # Directory where we want to save the results\n",
    "\n",
    "REFERENCE=\"/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/data/references/SS14.fa.gz\" # Bacteria reference genome\n",
    "HOST_GENOME=\"/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/data/references/GCF_000001405.36_GRCh38.p10_genomic.fna.gz\" # Host genome reference sequence; for human - ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.36_GRCh38.p10/GCF_000001405.36_GRCh38.p10_genomic.fna.gz\n",
    "\n",
    "THREADS=12 # Number of threads we will use in the analysis\n",
    "\n",
    "ADAPTER_R1=\"CTGTCTCTTATACACATCT\" # R1 3' adapeter, if any\n",
    "ADAPTER_R2=$ADAPTER_R1 # R2 3' adapter, if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Initial quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is always a good idea to run an initial quality check on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir -p $OUTPUT_DIR/qc/fastqc/raw\n",
    "\n",
    "ls $INPUT_DIR/*.gz\n",
    "\n",
    "fastqc --threads $THREADS --outdir $OUTPUT_DIR/qc/fastqc/raw $INPUT_DIR/*.gz\n",
    "\n",
    "multiqc --outdir $OUTPUT_DIR/qc/fastqc/raw $OUTPUT_DIR/qc/fastqc/raw/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we are working with DNA data and aiming for the results including the polymorphisms we should perform a careful preprocessing to remove the adapter sequences and perform quality trimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir -p $OUTPUT_DIR/data/preprocessed\n",
    "mkdir $OUTPUT_DIR/qc/cutadapt\n",
    "mkdir $OUTPUT_DIR/qc/fastqc/preprocessed\n",
    "\n",
    "cd $INPUT_DIR/\n",
    "\n",
    "for sample in *R1*.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "    echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "    echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "\n",
    "    echo \"Now I am processing ${FORWARD} as first in a pair and ${REVERSE} as a second in a pair.\"\n",
    "\n",
    "    cutadapt -a $ADAPTER_R1 -A $ADAPTER_R2 \\\n",
    "    --times 1 --quality-cutoff 15,15 --trim-n \\\n",
    "    --error-rate 0.10 -O 3 --minimum-length 35 --max-n 0 \\\n",
    "    --output $OUTPUT_DIR/data/preprocessed/${FORWARD%$extension}.trimmed.fastq.gz \\\n",
    "    --paired-output $OUTPUT_DIR/data/preprocessed/${REVERSE%$extension}.trimmed.fastq.gz \\\n",
    "    $FORWARD $REVERSE &>$OUTPUT_DIR/qc/cutadapt/${FORWARD%_R1${extension}}.cutadapt.out\n",
    "\n",
    "    echo \"Done processing $FORWARD and $REVERSE\"\n",
    "done\n",
    "\n",
    "multiqc --outdir $OUTPUT_DIR/qc/cutadapt $OUTPUT_DIR/qc/cutadapt/\n",
    "\n",
    "fastqc --threads $THREADS --outdir $OUTPUT_DIR/qc/fastqc/preprocessed $OUTPUT_DIR/data/preprocessed/*.gz\n",
    "\n",
    "multiqc --outdir $OUTPUT_DIR/qc/fastqc/preprocessed $OUTPUT_DIR/qc/fastqc/preprocessed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Host genome contamination removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Removal of the host genome DNA before the analysis speeds up the analysis and we will be working with much smaller files as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As is usuall, we have to generate a host genome DNA reference index. This is run just once for one reference and one BBMap version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir $(dirname $HOST_GENOME)/bbmap_index\n",
    "echo $(dirname $HOST_GENOME)/bbmap_index\n",
    "\n",
    "# If the host genome index does not exist create it\n",
    "if [ ! -d \"$(dirname $HOST_GENOME)/bbmap_index/$(basename $HOST_GENOME)\" ]; then\n",
    "    mkdir $(dirname $HOST_GENOME)/bbmap_index/$(basename $HOST_GENOME)\n",
    "    bbmap.sh ref=$HOST_GENOME -Xmx20g path=$(dirname $HOST_GENOME)/bbmap_index/$(basename $HOST_GENOME)\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once the index is done we can launch the host-genome removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir $OUTPUT_DIR/qc/bbmap\n",
    "\n",
    "cd $OUTPUT_DIR/data/preprocessed/\n",
    "\n",
    "for sample in *R1*trimmed.fastq.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "        echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "        echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "\n",
    "    echo \"Now I am processing ${FORWARD} as first in a pair and ${REVERSE} as a second in a pair with reference $HOST_GENOME.\"\n",
    "\n",
    "    # Start mapping\n",
    "    bbmap.sh threads=$THREADS -Xmx25g minid=0.95 maxindel=3 bandwidthratio=0.16 \\\n",
    "    bandwidth=12 quickmatch fast minhits=2 path=$(dirname $HOST_GENOME)/bbmap_index/$(basename $HOST_GENOME) unpigz pigz \\\n",
    "    in=${FORWARD} in2=${REVERSE} outu=$OUTPUT_DIR/data/preprocessed/${FORWARD%_R1${extension}}.clean.fastq.gz \\\n",
    "    outm=$OUTPUT_DIR/data/preprocessed/${FORWARD%_R1${extension}}.dirty.fastq.gz &>$OUTPUT_DIR/qc/bbmap/${FORWARD%_R1${extension}}.bbmap.out # qtrim=rl trimq=10 untrim  # We already have preprocessed data, no need for this\n",
    "\n",
    "    # De-interleave\n",
    "    reformat.sh -Xmx12g verifypaired in=$OUTPUT_DIR/data/preprocessed/${FORWARD%_R1${extension}}.clean.fastq.gz \\\n",
    "    out1=$OUTPUT_DIR/data/preprocessed/${FORWARD%${extension}}.clean.fastq.gz out2=$OUTPUT_DIR/data/preprocessed/${REVERSE%${extension}}.clean.fastq.gz\n",
    "\n",
    "    # Remove the host genome mapped reads (usefull for mapping precision)\n",
    "    rm $OUTPUT_DIR/data/preprocessed/${FORWARD%_R1${extension}}.clean.fastq.gz\n",
    "    rm $OUTPUT_DIR/data/preprocessed/${FORWARD%_R1${extension}}.dirty.fastq.gz\n",
    "done\n",
    "\n",
    "mkdir $OUTPUT_DIR/qc/fastqc/clean\n",
    "\n",
    "fastqc --threads $THREADS --outdir $OUTPUT_DIR/qc/fastqc/clean $OUTPUT_DIR/data/preprocessed/*.clean.fastq.gz\n",
    "\n",
    "multiqc --outdir $OUTPUT_DIR/qc/fastqc/clean $OUTPUT_DIR/qc/fastqc/clean/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bacteria contamination scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before we start with the alignment we can quickly scan for possible bacterial contamination in our dataset. This scan uses default StrainSeeker database which is most likely outdated but StrainSeeker offers a possibility to generate your [own index](http://bioinfo.ut.ee/strainseeker/index.php?r=site/page&view=manual#database) for the scan with their builder script. One advantage over tools such as [Kraken2](https://ccb.jhu.edu/software/kraken2/) (a great tool) is that is consumes much less RAM. However, the latest releases of MiniKraken2 could be used as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before we can use StrainSeeker we have to download the database to scan. We can use the database provided at the StrainSeeker webpage or create our own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "STRAINSEEKER_DB=/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/data/references/strainseekerdb\n",
    "\n",
    "mkdir $STRAINSEEKER_DB\n",
    "cd $STRAINSEEKER_DB/\n",
    "wget http://bioinfo.ut.ee/strainseeker/executables/ss_db_w32_4324.tar.gz\n",
    "tar xvzf ss_db_w32_4324.tar.gz\n",
    "\n",
    "STRAINSEEKER_DB=$STRAINSEEKER_DB/ss_db_w32_4324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have the database we can start the scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir $OUTPUT_DIR/qc/strainseeker\n",
    "\n",
    "cd $OUTPUT_DIR/data/preprocessed/\n",
    "\n",
    "for sample in *.clean.fastq.gz\n",
    "do \n",
    "    echo \"Working on sample $sample\"\n",
    "\n",
    "    echo \"Subsampling\"\n",
    "    seqtk sample -s100 $sample 1000000 > $sample.sub # Subsample fastq to 1M\n",
    "\n",
    "    echo \"Scanning\"\n",
    "    seeker.pl -i $sample.sub -d $STRAINSEEKER_DB -o $OUTPUT_DIR/qc/strainseeker/${sample%.fastq.gz}.seeker.txt\n",
    "\n",
    "    rm $sample.sub\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bacteria contamination scan - Kraken2 (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you have enough resources you can use [Kraken2](https://ccb.jhu.edu/software/kraken2/). It scans the most recent bacterial, viral and fungal databases (or their subselection) and evaluates the possible distributions of individual species. If you decided to use Kraken2, you have to build the Kraken2 database. Please note this might take a while and will consume quite a lof of [RAM](https://ccb.jhu.edu/software/kraken2/index.shtml?t=manual#kraken-2-databases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "KRAKEN2_DB=\"/mnt/nfs/home/323639/000000-My_Documents/VM-home/projects/honza/linda/pipeline/data/references/kraken2db\" # Directory with stored StrainSeeker database\n",
    "mkdir $KRAKEN2_DB\n",
    "\n",
    "DATE=$(date +'%m%d%Y') # Save current date -> database version\n",
    "echo $DATE\n",
    "\n",
    "kraken2-build --standard --threads $THREADS --db $KRAKEN2_DB/$DATE\n",
    "\n",
    "KRAKEN2_DB=$KRAKEN2_DB/06182019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have the database we can start the scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "THREADS=12\n",
    "OUTPUT_DIR=/mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results\n",
    "KRAKEN2_DB=/mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/reference/kraken2db/06182019\n",
    "REFERENCE=/mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/reference/SS14.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir -p $OUTPUT_DIR/qc/kraken2/reads\n",
    "\n",
    "cd $OUTPUT_DIR/data/preprocessed/\n",
    "\n",
    "for sample in *R1*.clean.fastq.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "        echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "        echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "\n",
    "    echo \"Now I am processing ${FORWARD} as first in a pair and ${REVERSE} as a second in a pair with database $KRAKEN2_DB.\"\n",
    "    \n",
    "    kraken2 --use-names --paired --threads $THREADS --gzip-compressed --classified-out $OUTPUT_DIR/qc/kraken2/reads/${FORWARD%R1*}.classified-out#.fastq --unclassified-out $OUTPUT_DIR/qc/kraken2/reads/${FORWARD%R1*}.unclassified-out#.fastq --output $OUTPUT_DIR/qc/kraken2/reads/${FORWARD%R1*}.kraken.txt --report $OUTPUT_DIR/qc/kraken2/reads/${FORWARD%R1*}.kraken.report.txt --db $KRAKEN2_DB $FORWARD $REVERSE\n",
    "\n",
    "    for output in $OUTPUT_DIR/qc/kraken2/reads/*classified*.fastq\n",
    "    do\n",
    "        gzip $output &\n",
    "    done \n",
    "done\n",
    "\n",
    "wait\n",
    "\n",
    "# Get only species lines\n",
    "for report in $OUTPUT_DIR/qc/kraken2/reads/*.kraken.report.txt\n",
    "do \n",
    "    grep -P 'unclassified|root|\\tS\\t' $report | sort -k1,1nr > ${report%.kraken.report.txt*}.S.kraken.report.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bacteria reference genome alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With host genome DNA cleaned data we can proceed to the alignment to the reference. Please note we apply few filterings already at this step, mainly the minimal mapping quality, pairing of the reads and read duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Prepare reference indexes\n",
    "if [[ ${REFERENCE##*.} == \"gz\" ]] # Uncompress the reference if it is in gz archive\n",
    "then\n",
    "    gunzip -c $REFERENCE > ${REFERENCE%.gz*}\n",
    "    REFERENCE=${REFERENCE%.gz*}\n",
    "fi\n",
    "\n",
    "if [[ `echo $REFERENCE | grep \".fna$\"` != \"\" ]] || [[ `echo $REFERENCE | grep \".fasta$\"` != \"\" ]] # Make a link to the original to have \".fa\" suffix\n",
    "then\n",
    "    ln -s $REFERENCE ${REFERENCE%.*}.fa\n",
    "fi\n",
    "\n",
    "bwa index $REFERENCE\n",
    "samtools faidx $REFERENCE\n",
    "\n",
    "cd $OUTPUT_DIR/data/preprocessed\n",
    "\n",
    "OUTPUT_DIR=${OUTPUT_DIR}/$(basename $REFERENCE .fa} # Adjust output directory to reflect the used reference genome\n",
    "\n",
    "mkdir -p $OUTPUT_DIR/alignment\n",
    "mkdir -p $OUTPUT_DIR/qc/alignment_stats\n",
    "\n",
    "for sample in *R1*clean.fastq.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "        echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "        echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "\n",
    "    # Start mapping\n",
    "    echo \"Now I am processing ${FORWARD} as first in a pair and ${REVERSE} as a second in a pair with reference $REFERENCE\"\n",
    "\n",
    "    bwa mem -t $THREADS -T 20 -v 1 -M -R \"@RG\\tID:1\\tLB:${sample%%.*}\\tPL:Illumina\\tSM:${sample%%.*}\\tPU:${sample%%.*}\" $REFERENCE ${FORWARD} ${REVERSE} | samtools view -F 4 -@ $THREADS -b - | samtools sort -@ $THREADS - > $OUTPUT_DIR/alignment/${FORWARD%R1*}.$(basename $REFERENCE .fa).bam \n",
    "\n",
    "    echo \"Mapping finished\"\n",
    "\n",
    "    echo \"Starting post-alignment processing and basic filtering\"\n",
    "    \n",
    "    cd $OUTPUT_DIR/alignment\n",
    "\n",
    "    i=${FORWARD%R1*}.$(basename $REFERENCE .fa).bam\n",
    "\n",
    "    samtools index -@ $THREADS $i # Index BAM files\n",
    "    samtools flagstat $i > $OUTPUT_DIR/qc/alignment_stats/${i%.*}.flagstat &\n",
    "    samtools view -@ $THREADS -h -F 12 -f 2 -F 256 -b $i | samtools sort -n -@ $THREADS - | samtools fixmate -O bam - - | samtools sort -@ $THREADS - > ${i%.*}.filt.bam # -F 2048 = supplementary alignment, \"chimeric/non-linear alignments\"; -q $MAPQ\n",
    "    samtools index -@ $THREADS ${i%.*}.filt.bam\n",
    "    samtools flagstat ${i%.*}.filt.bam > $OUTPUT_DIR/qc/alignment_stats/${i%.*}.filt.flagstat\n",
    "\n",
    "    echo \"Filtering finished\"\n",
    "\n",
    "    echo \"Starting indel realignment\"\n",
    "    # Indel realignment\n",
    "    # Create input seqence dictionary and index reference\n",
    "    rm ${REFERENCE%.*}.dict\n",
    "    picard CreateSequenceDictionary R=$REFERENCE O=${REFERENCE%.*}.dict\n",
    "\n",
    "    # Realign\n",
    "    i=${i%.*}.filt.bam\n",
    "\n",
    "    gatk -T RealignerTargetCreator --num_threads $THREADS -R $REFERENCE -I ${i} -o $OUTPUT_DIR/alignment/${i%.*}.forIndelRealigner.intervals # Prepare intervals\n",
    "    gatk -I ${i} -R $REFERENCE -T IndelRealigner -LOD 2.5 --consensusDeterminationModel USE_SW -targetIntervals $OUTPUT_DIR/alignment/${i%.*}.forIndelRealigner.intervals -o $OUTPUT_DIR/alignment/${i%.*}.indelRealigned.bam # Run re-alignment\n",
    "\n",
    "    samtools index -@ $THREADS ${i%.*}.indelRealigned.bam\n",
    "\n",
    "    rm $i\n",
    "    rm $i*\n",
    "    rm $OUTPUT_DIR/alignment/${i%.*}.forIndelRealigner.intervals\n",
    "\n",
    "    echo \"Finished indel realignment\"\n",
    "\n",
    "    echo \"Starting read duplicate removal\"\n",
    "\n",
    "    # Remove duplicates\n",
    "    i=${i%.*}.indelRealigned.bam\n",
    "\n",
    "    mkdir $OUTPUT_DIR/qc/picard_dup\n",
    "    \n",
    "    picard MarkDuplicates INPUT=$i OUTPUT=${i%.*}.dedup.bam METRICS_FILE=$OUTPUT_DIR/qc/picard_dup/${i%.*}.dedupStats.txt REMOVE_DUPLICATES=true OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 # Taggs ALL duplicates, PCR and optical and remove them\n",
    "\n",
    "    samtools index -@ $THREADS ${i%.*}.dedup.bam\n",
    "    samtools flagstat ${i%.*}.dedup.bam > $OUTPUT_DIR/alignment_stats/${i%.*}.dedup.flagstat\n",
    "\n",
    "    rm $i\n",
    "    rm $i*\n",
    "    \n",
    "    echo \"Finished read duplicate removal\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Post-alignment filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The most important part of the processing is the **post-alignment filtering**. `BWA MEM` is known to be very sensitive but not very specific. Right now, we have a lot of alignments which in reality do not belong to our reference. This is due to several factors used in BWA MEM, such as minimal length of alignment (default: 19, can be adjusted by `-k [INT]`), allowance of extensive soft-clipping, allowed hard-clipping and allowing a lot of mismatches. \n",
    "\n",
    "The simplest way to see the alignment artifacts and cross-mappings is to check the reference alignment coverage and check highly uneven coverage peaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We apply the following filters:\n",
    "\n",
    "1. To many mismatches\n",
    "    * max. 0.05% mismatches and\n",
    "    * max. 5 mismatches\n",
    "2. Very short alignments\n",
    "     * min 35 bp mapping (measured on the read, not the reference)\n",
    "3. Too much softclipped \n",
    "     * max 0.05% soft-clipped\n",
    "4. Supplementary/chimeric reads \n",
    "    * `samtools -F 2048` flag\n",
    "5. Too much hardclipped\n",
    "     * max 0.00% hard-clipped (no hard-clipping allowed)\n",
    "6. MAPQ 10 \n",
    "    * very often repetitive alignments\n",
    "7. MAPQ 40 \n",
    "    * get only high quality alignment\n",
    "8. Singletons \n",
    "    * remove singleton reads (not paired) after all the mapping filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_PERC_OF_MM=0.05 # Maximum percentage of mismatches compared to the read length - bad if we have to error-prone reads but helps to remove false-positives\n",
    "MAX_NUMBER_OF_MM=5 # Maximum number of mismatches\n",
    "MIN_LENGTH_MAPPED=35 # Remove mappings that mapped with too few bases (remove excesive soft-clipping)\n",
    "MAX_SOFTCLIP=0.05 # Maximal percentage of the reads allowed to be soft-clipped\n",
    "MAX_HARDCLIP=0.00 # Maximal percentage of the reads allowed to be hard-clipped\n",
    "MAPQ=10 # Minimal MAPQ for (probably) repetitive regions\n",
    "MAPQ_FINAL=40 # Minimal MAPQ for final results\n",
    "\n",
    "cd $OUTPUT_DIR/alignment\n",
    "\n",
    "mkdir $OUTPUT_DIR/tmp\n",
    "\n",
    "# Filter mappings\n",
    "for sample in *.filt.indelRealigned.dedup.bam\n",
    "do \n",
    "    echo \"Processing sample $sample\"\n",
    "\n",
    "    samtools index -@ $THREADS $sample\n",
    "\n",
    "    # 1) Remove too many mismatches\n",
    "    bamutils filter $sample ${sample%.*}.mm1.bam -failed ${sample%.*}.mm1.fail.txt -maximum_mismatch_ratio $MAX_PERC_OF_MM # Filter by perc. of mismatches; It's more filtering on edit distance = how many nucleotides have to be changed to get exactly the reference sequence; indels are counted as many times as they are \"long\"; error in the source https://github.com/ngsutils/ngsutils/pull/18\n",
    "    bamutils filter ${sample%.*}.mm1.bam ${sample%.*}.mm2.bam -failed ${sample%.*}.mm2.fail.txt -mismatch $MAX_NUMBER_OF_MM # Filter by num. of mismatches\n",
    "\n",
    "    cat ${sample%.*}.mm1.fail.txt ${sample%.*}.mm2.fail.txt > ${sample%.*}.mm.fail.txt # Merge mapping filtered by mismatches\n",
    "\n",
    "    # Use extracted filtered read name and filter it out from the original bam but ONLY when the mismatches filtering had some results\n",
    "    if [ -s ${sample%.*}.mm.fail.txt ]\n",
    "    then\n",
    "        cat ${sample%.*}.mm.fail.txt | awk '{print $1}' | sort -T $OUTPUT_DIR/tmp --parallel=$THREADS | uniq > ${sample%.*}.mm.fail.txt.tmp\n",
    "        echo \"Number of too much mismatched reads is\" `wc -l ${sample%.*}.mm.fail.txt.tmp` \"for sample \" $sample\n",
    "        picard FilterSamReads I=$sample O=${sample%.*}.mm.filtOut.bam READ_LIST_FILE=${sample%.*}.mm.fail.txt.tmp FILTER=includeReadList # Include reads\n",
    "        rm ${sample%.*}.mm.fail.txt.tmp\n",
    "    else\n",
    "        echo \"There are none to much mismatched reads with \" $MAX_PERC_OF_MM \" % and \" $MAX_NUMBER_OF_MM \" mismatches for sample \" $sample\". Nothing to report.\"\n",
    "    fi\n",
    "\n",
    "    # 2) Remove too short alignment\n",
    "    # Filter out mappings that mapped with length shorter than MIN_LENGTH_MAPPED https://www.biostars.org/p/12406/ - this filters the mapping by calculating the length of mapping on the read itself; example 106S8M1D21M14S with MIN_LENGTH_MAPPED=30 is filtered out because 8M+21M=29\n",
    "    # Another filtering by mapped read length could be taken from here https://www.biostars.org/p/151510/ - this filters the mapping by calculating the length of mapping on the reference; example 106S8M1D21M14S with MIN_LENGTH_MAPPED=30 is NOT filtered out because 8M+1D+21M=30, it is filtered out when set to MIN_LENGTH_MAPPED=31\n",
    "    #samjs.jar -e '!record.readUnmappedFlag  && record.cigar.referenceLength  >= $MIN_LENGTH_MAPPED '$sample | samtools view -@ $THREADS -b -o ${sample%.*}.short.bam -\n",
    "    samtools view -h -@ $THREADS ${sample%.*}.mm2.bam | perl -slane '$l = 0; $F[5] =~ s/(\\d+)[MX=DN]/$l+=$1/eg; print if $l < $MIN_LENGTH_MAPPED or /^@/' -- -MIN_LENGTH_MAPPED=$MIN_LENGTH_MAPPED | samtools view -@ $THREADS -b - > ${sample%.*}.short.filtOut.bam &\n",
    "    samtools view -h -@ $THREADS ${sample%.*}.mm2.bam | perl -slane '$l = 0; $F[5] =~ s/(\\d+)[MX=DN]/$l+=$1/eg; print if $l >= $MIN_LENGTH_MAPPED or /^@/' -- -MIN_LENGTH_MAPPED=$MIN_LENGTH_MAPPED | samtools view -@ $THREADS -b - > ${sample%.*}.short.bam\n",
    "\n",
    "    # 3) Too much softclipped\n",
    "    # Running it on the whole file and saving it creates error in BAM validation; we have to just take the read names from here and remove them from the alignment\n",
    "    bamutils removeclipping ${sample%.*}.short.bam ${sample%.*}.scf.bam.tmp\n",
    "    samtools view -@ $THREADS ${sample%.*}.scf.bam.tmp | grep 'ZC:f:' | awk '{for (i=1;i<=NF;i++){if ($sample ~/ZC:f:/) {print $1, $sample}}}' | sed 's/ZC:f://' | awk -v MAX_SOFTCLIP=\"$MAX_SOFTCLIP\" ' $2 > MAX_SOFTCLIP {print $1}' > ${sample%.*}.read_names_to_remove_highSoftClip.txt.tmp # Get only softclipped reads above the threshold\n",
    "    rm ${sample%.*}.scf.bam.tmp # Remove temporary BAMs\n",
    "    cat ${sample%.*}.read_names_to_remove_highSoftClip.txt.tmp | cut -f 1 | sort -T $OUTPUT_DIR/tmp --parallel=$THREADS | uniq > ${sample%.*}.read_names_to_remove_highSoftClip.txt # Get unique read names with softclipping!\n",
    "    #cat ${sample%.*}.read_names_to_remove_highSoftClip.txt | cut -f 1 | sort -T $OUTPUT_DIR/tmp --parallel=$THREADS | uniq -d > tmp; mv tmp ${sample%.*}.read_names_to_remove_highSoftClip.txt # Get unique read names with softclipping if whole pair failed the filtering!\n",
    "    rm ${sample%.*}.read_names_to_remove_highSoftClip.txt.tmp\n",
    "\n",
    "    # Use extracted filtered read name and filter it out from the original bam but ONLY when the soft clipping filtering had some results\n",
    "    if [ -s ${sample%.*}.read_names_to_remove_highSoftClip.txt ]\n",
    "    then\n",
    "        echo \"Number of too much soft clipped reads is\" `wc -l ${sample%.*}.read_names_to_remove_highSoftClip.txt` \"for sample \" $sample\n",
    "        picard FilterSamReads I=${sample%.*}.short.bam O=${sample%.*}.scf.filtOut.bam READ_LIST_FILE=${sample%.*}.read_names_to_remove_highSoftClip.txt FILTER=includeReadList & # Include reads\n",
    "        picard FilterSamReads I=${sample%.*}.short.bam O=${sample%.*}.scf.bam READ_LIST_FILE=${sample%.*}.read_names_to_remove_highSoftClip.txt FILTER=excludeReadList # Exclude reads\n",
    "    else\n",
    "        echo \"There are none to much soft clipped reads with \" $MAX_SOFTCLIP \" % soft clipping for sample \" $sample. Continue without filtering.\n",
    "        mv ${sample%.*}.short.bam ${sample%.*}.scf.bam\n",
    "    fi\n",
    "\n",
    "    samtools index -@ $THREADS ${sample%.*}.scf.bam\n",
    "\n",
    "    # 4) Supplementary/chimeric alignment\n",
    "    samtools view -@ $THREADS -h -f 2048 -b ${sample%.*}.scf.bam > ${sample%.*}.sup.filtOut.bam & # get -F 2048 \"chimeric/non-linear alignments\" - might be interesting for translocations; possible overlap with hardclipping \n",
    "    samtools view -@ $THREADS -h -F 2048 -b ${sample%.*}.scf.bam > ${sample%.*}.sup.bam # remove -F 2048 \"chimeric/non-linear alignments\" - might be interesting for translocations; possible overlap with hardclipping\n",
    "\n",
    "    # 5) Hardclipped\n",
    "    samtools view -@ $THREADS -h ${sample%.*}.sup.bam | awk '$6 ~ /H/{print}' | samtools view -bh - > ${sample%.*}.hcf.filtOut.bam & # Get only hardclipped mappings; hardclipped alignments might mean the part of the alignment that is hardclipped might map to different part of the genome - possible chimeric reads? https://www.biostars.org/p/109333/\n",
    "    samtools view -@ $THREADS -h ${sample%.*}.sup.bam | awk '$6 !~ /H/{print}' | samtools view -bh - > ${sample%.*}.hcf.bam # https://www.biostars.org/p/137461/\n",
    "\n",
    "    # 6) MAPQ10  very often repetitive alignments\n",
    "    samtools view -@ $THREADS -h ${sample%.*}.sup.bam | awk -v var=\"$MAPQ\" '$5 < var || $1 ~ /^@/' | samtools view -b - > ${sample%.*}.MAPQ${MAPQ}.filtOut.bam &\n",
    "    samtools view -@ $THREADS -h -bq $MAPQ ${sample%.*}.sup.bam > ${sample%.*}.MAPQ${MAPQ}.bam # BWA-MEM -T settings should filter all low MAPQ mappings; -F 2048 \"chimeric/non-linear alignments\" - might be interesting for translocations\n",
    "\n",
    "    # 7) MAPQ40  Only high quality alignments\n",
    "    samtools view -@ $THREADS -h ${sample%.*}.MAPQ${MAPQ}.bam | awk -v var=\"$MAPQ_FINAL\" '$5 < var || $1 ~ /^@/' | samtools view -b - > ${sample%.*}.MAPQ${MAPQ_FINAL}.filtOut.bam &\n",
    "    samtools view -@ $THREADS -h -bq $MAPQ_FINAL ${sample%.*}.MAPQ${MAPQ}.bam > ${sample%.*}.MAPQ${MAPQ_FINAL}.bam # Get only very high quality mappings\n",
    "\n",
    "    # 8) Singletons\n",
    "    # Remove reads that remained as singletons after all filtering steps - works only for paired-end sequencing!\n",
    "    samtools view -@ $THREADS ${sample%.*}.MAPQ${MAPQ_FINAL}.bam | cut -f 1 | sort -T $OUTPUT_DIR/tmp --parallel=$THREADS | uniq -u > ${sample%.*}.MAPQ${MAPQ_FINAL}.singleAfterFilt.txt\n",
    "\n",
    "    if [ -s ${sample%.*}.MAPQ${MAPQ_FINAL}.singleAfterFilt.txt ]\n",
    "    then\n",
    "        echo \"Number of singleton reads after filtering is\" `wc -l ${sample%.*}.MAPQ${MAPQ_FINAL}.singleAfterFilt.txt` \"for sample \" $sample\n",
    "        picard FilterSamReads I=${sample%.*}.MAPQ${MAPQ_FINAL}.bam O=${sample%.*}.singletons.filtOut.bam READ_LIST_FILE=${sample%.*}.MAPQ${MAPQ_FINAL}.singleAfterFilt.txt FILTER=includeReadList & # Include reads\n",
    "        picard FilterSamReads I=${sample%.*}.MAPQ${MAPQ_FINAL}.bam O=${sample%.*}.MAPQ${MAPQ_FINAL}.bam.tmp READ_LIST_FILE=${sample%.*}.MAPQ${MAPQ_FINAL}.singleAfterFilt.txt FILTER=excludeReadList # Exclude reads\n",
    "        mv ${sample%.*}.MAPQ${MAPQ_FINAL}.bam.tmp ${sample%.*}.MAPQ${MAPQ_FINAL}.bam\n",
    "    else\n",
    "        echo \"There are none singleton reads after filtering for sample \" $sample. Continue without filtering.\n",
    "    fi\n",
    "\n",
    "    samtools index -@ $THREADS ${sample%.*}.MAPQ${MAPQ_FINAL}.bam\n",
    "\n",
    "    sleep 60 # wait/sleep for one minute for the jobs to finish (if they didn't)\n",
    "\n",
    "done\n",
    "\n",
    "for sample in $OUTPUT_DIR/alignment/*.bam\n",
    "do\n",
    "    samtools index -@ $THREADS $sample\n",
    "done\n",
    "\n",
    "# Do some cleaning\n",
    "rm $OUTPUT_DIR/alignment/*.bam.tmp $OUTPUT_DIR/alignment/*.read_names_to_remove_highSoftClip.txt $OUTPUT_DIR/alignment/*.reads $OUTPUT_DIR/alignment/*.singleAfterFilt.txt $OUTPUT_DIR/alignment/*.fail.txt\n",
    "\n",
    "mkdir -p $OUTPUT_DIR/alignment/filtered/filtOut\n",
    "mkdir -p $OUTPUT_DIR/alignment/filtered/filt\n",
    "\n",
    "mv $OUTPUT_DIR/alignment/*.filtOut.bam* $OUTPUT_DIR/alignment/filtered/filtOut/\n",
    "mv $OUTPUT_DIR/alignment/* $OUTPUT_DIR/alignment/filtered/filt/\n",
    "mv $OUTPUT_DIR/alignment/filtered/filt/*.MAPQ40.bam* $OUTPUT_DIR/alignment/filtered/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please note that the filtering applied is rather strict. We might lose some true positive mappings but in this case we rather focus on strongly supported alignments to be sure we are detecting what we want to detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Alignment statistics and reference genome coverage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One of the the quality checks after the filtering and before all the other steps is the genome coverage statistics...and of course general mapping statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run mapping QC\n",
    "COVER_INT=\"-ct 3 -ct 5 -ct 10\" # Intervals of coverage to make the statistics for, can be multiple values; --summaryCoverageThreshold\n",
    "\n",
    "cd $OUTPUT_DIR/alignment/filtered\n",
    "\n",
    "# Get general alignment statistics\n",
    "mkdir $OUTPUT_DIR/qc/qualimap\n",
    "\n",
    "for sample in *.MAPQ${MAPQ_FINAL}.bam\n",
    "do\n",
    "    # PDF version is better for browsing\n",
    "    qualimap bamqc -bam $sample -nt $THREADS -c -outformat PDF -outdir $OUTPUT_DIR/qc/qualimap -outfile ${sample%.*}.qualimap.pdf\n",
    "    mv $OUTPUT_DIR/qc/qualimap/genome_results.txt $OUTPUT_DIR/qc/qualimap/${sample%.*}.genome_results.txt\n",
    "    # HTML version is necessary for multiQC\n",
    "    mkdir -p $OUTPUT_DIR/qc/qualimap/html/${sample%.*}\n",
    "    qualimap bamqc -bam $sample -nt $THREADS -c -outformat HTML -outdir $OUTPUT_DIR/qc/qualimap/html/${sample%.*} # Has to be redirected to separate folder for each file\n",
    "done\n",
    "\n",
    "multiqc -o $OUTPUT_DIR/qc/qualimap $OUTPUT_DIR/qc/qualimap/\n",
    "\n",
    "# Calculate the coverage\n",
    "mkdir -p $OUTPUT_DIR/qc/coverage\n",
    "\n",
    "# Prepare indexes\n",
    "samtools faidx $REFERENCE\n",
    "rm ${REFERENCE%.*}.dict\n",
    "picard CreateSequenceDictionary R=$REFERENCE O=${REFERENCE%.*}.dict\n",
    "\n",
    "# Run GATK DepthOfCoverage\n",
    "ls *.MAPQ40.bam | tr ' ' '\\n' > $OUTPUT_DIR/alignment/filtered//input_bams.list\n",
    "\n",
    "echo \"Going to process files\" `cat $OUTPUT_DIR/alignment/filtered//input_bams.list`\n",
    "\n",
    "gatk \\\n",
    "-T DepthOfCoverage \\\n",
    "-R $REFERENCE \\\n",
    "-I $OUTPUT_DIR/alignment/filtered/input_bams.list \\\n",
    "-o $OUTPUT_DIR/qc/coverage/$(basename $REFERENCE .fa)${INPUT_BAM%.bam}.coverage \\\n",
    "$COVER_INT # --outputFormat csv # Default is readable table (rtable)\n",
    "\n",
    "rm $OUTPUT_DIR/alignment/filtered/input_bams.list\n",
    "\n",
    "pigz -p $THREADS $OUTPUT_DIR/qc/coverage/*.coverage\n",
    "\n",
    "# Count number of mapped reads - we have the same information in Qualimap report\n",
    "echo \"Number of mapped read pairs (-F 3852 -f 2 -q 40 = read mapped in proper pair ; NOT read unmapped, mate unmapped not primary alignment, read fails platform/vendor quality checks, read is PCR or optical duplicate, supplementary alignment)\" > $OUTPUT_DIR/qc/coverage/num_reads.txt\n",
    "\n",
    "for sample in *.MAPQ40.bam\n",
    "do\n",
    "    echo -ne $sample ' '\n",
    "    samtools view -@ $THREADS -F 3852 -f 2 -q 40 $sample | cut -f 1 | sort -T $OUTPUT_DIR/tmp | uniq | wc -l\n",
    "done >> $OUTPUT_DIR/qc/coverage/num_reads.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "### Alignment consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this phase, we can generate the mapping consensus. Please not this steps is closely related to the previous step as it will take only the filtered mappings into consideration. Here, we use a 'simple' variant call performed by `samtools`&`bcftools` and `GATK`. You might consider alternating this step with more sophisticated variant call if you think it is necessary. The difference is that the \"samtools\" version gives you lower-case letters where coverage was low and *N* where there was no coverage. Here, we convert all low-coverage positions to *n* (lower-case). The \"GAKT\" version copies the reference sequence where is no coverage. \"samtools\" version doesn't like to include indels whereas \"GATK\" version should be OK with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Fix reference name and SAM header (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`bcftools` and `vcfutils` might have problem with \".\" or any \"strange\" symbol in the reference name. If you haven't \"fix\" your reference name you can do it here but remember you have to replace it in the SAM/BAM header as well. Or go back to the beginning and redo the whole analysis (joke)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Replace the reference name\n",
    "sed -i 's/gi_511533127_gb_CP004011\\.1__Treponema_pallidum_subsp\\._pallidum_SS14,_complete_genome/gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome/g' $REFERENCE \n",
    "\n",
    "# Replace the SAM header\n",
    "for sample in *.filt.indelRealigned.dedup.MAPQ40.bam\n",
    "do\n",
    "    samtools view -@ $THREADS -H $sample > $sample.header.sam  # extract header only\n",
    "\n",
    "    sed -i 's/gi_511533127_gb_CP004011\\.1__Treponema_pallidum_subsp\\._pallidum_SS14,_complete_genome/gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome/g' $sample.header.sam\n",
    "\n",
    "    samtools reheader $sample.header.sam $sample > $sample.tmp\n",
    "    mv $sample.tmp $sample\n",
    "\n",
    "    rm $sample.header.sam\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Mapping consensus ~ alignment-guided assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MIN_COVER=3 # All bases bellow this coverage are converted to ns\n",
    "PLOIDY=1 # Ploidy for the bcftools\n",
    "\n",
    "mkdir -p $OUTPUT_DIR/consensus/other\n",
    "\n",
    "# Make sure we have reference index and dictionary (! have to redo if you used the previous \"fix\" step)\n",
    "samtools faidx $REFERENCE\n",
    "rm ${REFERENCE%.*}.dict\n",
    "picard CreateSequenceDictionary R=$REFERENCE O=${REFERENCE%.*}.dict\n",
    "\n",
    "for sample in *.filt.indelRealigned.dedup.MAPQ40.bam\n",
    "do\n",
    "    samtools index -@ $THREADS $sample\n",
    "    samtools mpileup --max-depth 10000 -E --min-BQ 13 --fasta-ref $REFERENCE --min-MQ 40 -g -u --max-idepth 100000 --min-ireads 5 --gap-frac 0.002 --excl-flags UNMAP,SECONDARY,QCFAIL,DUP --output-tags DP,AD,ADF,ADR,SP,INFO/AD,INFO/ADF,INFO/ADR --reference $REFERENCE $sample | bcftools call --ploidy $PLOIDY -c --keep-masked-ref --output-type v --threads $THREADS - > $OUTPUT_DIR/consensus/other/${sample%.*}.vcf\n",
    "\n",
    "    cat $OUTPUT_DIR/consensus/other/${sample%.*}.vcf | vcfutils.pl vcf2fq -d $MIN_COVER | seqtk seq -A - > $OUTPUT_DIR/consensus/${sample%.*}.cns.def.fasta\n",
    "\n",
    "    # Convert all low-coverage (=lower-case) positions to \"n\"\n",
    "    sed -e '/^>/! s/[[:lower:]]/n/g' $OUTPUT_DIR/consensus/${sample%.*}.cns.def.fasta > $OUTPUT_DIR/consensus/${sample%.*}.cns.final.fasta\n",
    "\n",
    "    gatk -T FastaAlternateReferenceMaker -R $REFERENCE -o $OUTPUT_DIR/consensus/${sample%.*}.cns.gatk.fasta --variant $OUTPUT_DIR/consensus/other/${sample%.*}.vcf\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### BAM downsampling (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In some cases, our resulting SAM/BAM is very deep which causes problems during the subsequent analysis. An option to lower down the computational demands is to downsample to a specific depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_COVER=250 # Set maximum coverage to put the limit on\n",
    "\n",
    "for sample in *.filt.indelRealigned.dedup.MAPQ40.bam\n",
    "do\n",
    "    java -jar -Xmx4g $CONDA_PREFIX/bin/sortsamrefname.jar --tmpDir $OUTPUT_DIR/tmp $sample |  java -jar -Xmx4g $CONDA_PREFIX/bin/downsamplebam.jar -n $MAX_COVER | samtools sort -@ $THREADS - > ${sample%.bam*}.downsamp${MAX_COVER}.bam\n",
    "    samtools index -@ $THREADS ${sample%.bam*}.downsamp${MAX_COVER}.bam\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variant call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To get the most relevant variants directly from the alignments we could either use the variants used for the consensus generation or we can use probably more suitable tools for bacteria variant call such as [`freebayes`](https://github.com/ekg/freebayes). The reason why we don't use other tools than `samtools`/`bcftools` for the generation of consensus is the compatibility of the approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MIN_DP=$MIN_COVER # Set minimal coverage depth of the mapping\n",
    "QUAL_SET=50 # Set minimal variant quality for the most certain variants; default it 20\n",
    "\n",
    "mkdir -p $OUTPUT_DIR/variants/freebayes/stats\n",
    "\n",
    "for sample in *filt.indelRealigned.dedup.MAPQ40.bam\n",
    "do\n",
    "    echo \"Processing $sample\"\n",
    "    \n",
    "    samtools index $sample\n",
    "\n",
    "    freebayes --bam $sample --vcf $OUTPUT_DIR/variants/freebayes/${sample%.*}.full.vcf --fasta-reference $REFERENCE --theta 0.001 --ploidy $PLOIDY --min-mapping-quality 10 --min-base-quality 15 --min-alternate-fraction 0.01 --min-alternate-count 2 --genotype-qualities --report-all-haplotype-alleles # You can add \"--report-monomorphic\" to get all positions\n",
    "done\n",
    "\n",
    "# Variant post-processing and filtering\n",
    "cd $OUTPUT_DIR/variants/freebayes/\n",
    "\n",
    "for sample in *full.vcf\n",
    "do\n",
    "    echo \"Processing \" $sample\n",
    "\n",
    "    # GATK filtering\n",
    "    gatk -T VariantFiltration -R $REFERENCE -o $OUTPUT_DIR/variants/freebayes/${sample%.full*}.filt.vcf --variant:VCF $sample --filterExpression \"DP < ${MIN_DP}\" --filterName \"LowCoverage\" --filterExpression \"QUAL > 0 && QUAL < 20\" --filterName \"VeryLowQual\" --filterExpression \"QUAL > 20 && QUAL < ${QUAL_SET}\" --filterName \"LowQual\" --filterExpression \"QUAL == 0\" --filterName \"TechnicalQual\" # This might be too strict for FreeBayes\n",
    "    # gatk -T VariantFiltration -R $REFERENCE -o ${sample%.full*}.filt.vcf --variant:VCF $sample --filterExpression \"DP < ${MIN_DP}\" --filterName \"LowCoverage\" --filterExpression \"QUAL > 0 && QUAL < 20\" --filterName \"VeryLowQual\" --filterExpression \"QUAL == 0\" --filterName \"TechnicalQual\" # This would be the way FreeBayes author recommends to use the filtering\n",
    "\n",
    "    mv ${sample%.full*}.filt.vcf $sample\n",
    "    rm ${sample%.full*}.filt.vcf.idx\n",
    "    \n",
    "    # Get only variants (PASS filtering)\n",
    "    grep \"^#\" $sample > ${sample%.full*}.var.vcf # Get only header\n",
    "    awk '$7 == \"PASS\" {print $0}' $sample >> ${sample%.full*}.var.vcf\n",
    "\n",
    "    # Get only SNPs and/or indels\n",
    "#    vcffilter -f \"TYPE = snp\" ${sample%.full*}.var.vc > ${sample%.full*}.var.snp.vcf # Get only SNP\n",
    "#    vcffilter -f \"( TYPE = ins | TYPE = del )\" ${sample%.full*}.var.vcf > ${sample%.full*}.var.indel.vcf # Get only indels\n",
    "\n",
    "    # Convert vct to tab vcftools\n",
    "    cat ${sample%.full*}.var.vcf | vcf-to-tab > ${sample%.full*}.var.tsv\n",
    "\n",
    "    # Get stats of the variant calling\n",
    "    # Stats from raw and filtered SNPs\n",
    "    vcfstats $sample > $OUTPUT_DIR/variants/freebayes/stats/${sample%.vcf}.stats.txt\n",
    "    vcfstats ${sample%.full*}.var.vcf > $OUTPUT_DIR/variants/freebayes/stats/${sample%.full*}.var.stats.txt\n",
    "\n",
    "    # Compare ts/tv ration between high/low quality variants\n",
    "    echo $sample > $OUTPUT_DIR/variants/freebayes/stats/${sample%.vcf}.ratio.stats.txt\n",
    "    echo \"Low quality variants\" >> $OUTPUT_DIR/variants/freebayes/stats/${sample%.*}.ratio.stats.txt # Low quality variants\n",
    "    vcffilter -f \"QUAL < 20\" $sample | vcfstats | grep \"ts\\|bial\" >> $OUTPUT_DIR/variants/freebayes/stats/${sample%.vcf}.ratio.stats.txt\n",
    "    echo \"High quality variants\" >> $OUTPUT_DIR/variants/freebayes/stats/${sample%.vcf}.ratio.stats.txt # High quality variants\n",
    "    vcffilter -f \"QUAL > 20\" $sample | vcfstats | grep \"ts\\|bial\" >> $OUTPUT_DIR/variants/freebayes/stats/${sample%.vcf}.ratio.stats.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variant annotation (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Having variants in VCF is nice but often you might be interested what is their effect or purpose. Unless you imidiately know the important positions variant annotation might bring you some additional information. [SnpEff](http://snpeff.sourceforge.net/) allows you to build your own annotation database and apply it to your VCF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we build the annotation database. This has to be done only once per genome. Note: there are some pre-loaded annotations in SnpEff but since we might be using different genome version it might be safer to generate our own database. You can generate the database with GFF and FASTA (hint [here](http://lab.loman.net/2012/11/16/how-to-get-snpeff-working-with-bacterial-genomes-from-ncbi/)) or you can do it from **GenBank full** format (suffix **.gbff** at the GenBank ftp). The advantage of going for **GenBank full** is that both gene annotation and genome sequence is included in one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2//data/SS14_CP004011.1\n",
      "(treponema) \n",
      "(treponema) gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome\n",
      "(treponema) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "echo $ANNOT_DIR\n",
    "echo $seq_name\n",
    "echo $fasta_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) (treponema) /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/\n",
      "(treponema) (treponema) (treponema) (treponema) 00:00:00\tSnpEff version SnpEff 4.3t (build 2017-11-24 10:18), by Pablo Cingolani\n",
      "00:00:00\tCommand: 'build'\n",
      "00:00:00\tBuilding database for 'SS14_CP004011.1'\n",
      "00:00:00\tReading configuration file 'snpEff.config'. Genome: 'SS14_CP004011.1'\n",
      "00:00:00\tReading config file: /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/snpEff.config\n",
      "00:00:00\tdone\n",
      "Chromosome: 'gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome'\tlength: 1139569\n",
      "\n",
      "\tCreate exons from CDS (if needed): ...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\tExons created for 975 transcripts.\n",
      "\n",
      "\tDeleting redundant exons (if needed): \n",
      "\t\tTotal transcripts with deleted exons: 0\n",
      "\n",
      "\tCollapsing zero length introns (if needed): \n",
      "\t\tTotal collapsed transcripts: 0\n",
      "\t\tAdding genomic sequences to exons: \tDone (975 sequences added, 0 ignored).\n",
      "\n",
      "\tAdjusting transcripts: \n",
      "\tAdjusting genes: \n",
      "\tAdjusting chromosomes lengths: \n",
      "\tRanking exons: \n",
      "\tCreate UTRs from CDS (if needed): \n",
      "\tRemove empty chromosomes: \n",
      "\n",
      "\tMarking as 'coding' from CDS information: \n",
      "\tDone: 0 transcripts marked\n",
      "00:00:01\tCaracterizing exons by splicing (stage 1) : \n",
      "\t\n",
      "00:00:01\tCaracterizing exons by splicing (stage 2) : \n",
      "\t00:00:01\tdone.\n",
      "00:00:01\t[Optional] Rare amino acid annotations\n",
      "00:00:01\tWarning: Cannot read optional protein sequence file '/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/./data/SS14_CP004011.1/protein.fa', nothing done.\n",
      "00:00:01\tProtein check file: '/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/./data/SS14_CP004011.1/genes.gbk'\n",
      "\n",
      "00:00:01\tChecking database using protein sequences\n",
      "00:00:01\tComparing Proteins...\n",
      "\tLabels:\n",
      "\t\t'+' : OK\n",
      "\t\t'.' : Missing\n",
      "\t\t'*' : Error\n",
      "\t+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++*+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\t++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\tProtein check:\tSS14_CP004011.1\tOK: 974\tNot found: 0\tErrors: 1\tError percentage: 0.10256410256410256%\n",
      "00:00:01\tSaving database\n",
      "00:00:01\t[Optional] Reading regulation elements: GFF\n",
      "00:00:01\tWarning: Cannot read optional regulation file '/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/./data/SS14_CP004011.1/regulation.gff', nothing done.\n",
      "00:00:01\t[Optional] Reading regulation elements: BED \n",
      "00:00:01\tCannot find optional regulation dir '/mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/./data/SS14_CP004011.1/regulation.bed/', nothing done.\n",
      "00:00:01\t[Optional] Reading motifs: GFF\n",
      "00:00:01\tWarning: Cannot open PWMs file /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/share/snpeff-4.3.1t-2/./data/SS14_CP004011.1/pwms.bin. Nothing done\n",
      "00:00:01\tDone\n",
      "00:00:01\tLogging\n",
      "00:00:02\tChecking for updates...\n",
      "\n",
      "\n",
      "NEW VERSION!\n",
      "\tThere is a new SnpEff version available: \n",
      "\t\tVersion      : 4.4\n",
      "\t\tRelease date : 2019-01-26\n",
      "\t\tDownload URL : http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip\n",
      "\n",
      "00:00:03\tDone.\n",
      "(treponema) (treponema) #-----------------------------------------------\n",
      "# Genome name                : 'Treponema pallidum subsp. pallidum SS14'\n",
      "# Genome version             : 'SS14_CP004011.1'\n",
      "# Genome ID                  : 'SS14_CP004011.1[0]'\n",
      "# Has protein coding info    : true\n",
      "# Has Tr. Support Level info : true\n",
      "# Genes                      : 1032\n",
      "# Protein coding genes       : 975\n",
      "#-----------------------------------------------\n",
      "# Transcripts                : 975\n",
      "# Avg. transcripts per gene  : 0.94\n",
      "# TSL transcripts            : 0\n",
      "#-----------------------------------------------\n",
      "# Checked transcripts        : \n",
      "#               AA sequences :    974 ( 99.90% )\n",
      "#              DNA sequences :      0 ( 0.00% )\n",
      "#-----------------------------------------------\n",
      "# Protein coding transcripts : 975\n",
      "#              Length errors :      0 ( 0.00% )\n",
      "#  STOP codons in CDS errors :      0 ( 0.00% )\n",
      "#         START codon errors :      0 ( 0.00% )\n",
      "#        STOP codon warnings :      0 ( 0.00% )\n",
      "#              UTR sequences :      0 ( 0.00% )\n",
      "#               Total Errors :      0 ( 0.00% )\n",
      "# WARNING                    : No protein coding transcript has UTR\n",
      "#-----------------------------------------------\n",
      "# Cds                        : 975\n",
      "# Exons                      : 975\n",
      "# Exons with sequence        : 975\n",
      "# Exons without sequence     : 0\n",
      "# Avg. exons per transcript  : 1.00\n",
      "#-----------------------------------------------\n",
      "# Number of chromosomes      : 1\n",
      "# Chromosomes                : Format 'chromo_name size codon_table'\n",
      "#\t\t'gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome'\t1139569\tBacterial_and_Plant_Plastid\n",
      "#-----------------------------------------------\n",
      "\n",
      "gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome:3-1397, strand:1, id:TPASS_20001, name:dnaA\n",
      "Transcipts:\n",
      "\tgi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome:3-1397, strand: +, id:TPASS_20001, Protein, AA check\n",
      "\t\tExons:\n",
      "\t\tgi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome:3-1397 'EXON_gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome_3_1397', rank: 1, frame: ., sequence: atggacgcagtagggtatgaagtattctggaacgagacactcagccagatacggagtgaatcgaccgaagcagaatttaacatgtggtttgctcatttgttctttatcgcatcttttgaaaacgctatcgaaatagcagtaccttcagactttttccgaatacagtttagccaaaaatatcaagaaaagcttgagcgcaagttcctcgaactttctggacaccccattaaacttttgtttgccgttaaaaaaggcacccctcatggaaatactgctccccccaaacacgtgcatacctacctggagaaaaactctcctgcagaggttccttccaaaaagagctttcaccccgacctgaacagagactataccttcgagaactttgtatccggagaagaaaccaaattcagccatagcgctgctatctccgtatcaaaaaacccaggcacttcctacaatccgttacttatctacggtggagtgggactaggaaaaacccaccttatgcaggctattggacacgagatctacaagacaacagacctgaacgtcatatacgtcactgcggagaattttggaaatgaattcatttccacattactcaataaaaagacccaggattttaaaaaaaaataccgctacaccgcggatgtacttcttatagatgacattcatttttttgaaaacaaagacggattacaagaagagcttttctatacgttcaacgaacttttcgagaaaaaaaaacaaattatctttacctgcgacaggcctgtacaagaattgaaaaatctctcttctcgcttacgctcgaggtgctcccgagggcttagcactgatctgaatatgccatgttttgaaacgcgctgtgctatcttgattaaaaaaatacaaaactataacagcacctatcctcacaaagccatccacatttcagacgatgttgtccgacttgtttctgaaaacatttcttcaaatatcagggatcttgagggggcattaacaaaaattatcgctttcattgaagtgtcgggatccatcacgatagatatcgttccctctctcctaaaagagttcttcctctctgcaaggccaaaacacatcacagtagaaactattcttcatgtagttgcagatcactttaacatttcgtattcagatctaaagggtaagaaacgcaataaaagcgttgtttatcctcggcaaatcgctatgtttctctcaaaggaactgacagagctctccactactgaacttggtatcgaatttggtggcagagatcattcaaccgtcatttacggatgtcaaaaaatagaaggagaaattctcactaatccttcgttacaggcaaatcttgatttgctgaaaagtaaagttcaagattcaatccgctag\n",
      "\t\tCDS     :\tatggacgcagtagggtatgaagtattctggaacgagacactcagccagatacggagtgaatcgaccgaagcagaatttaacatgtggtttgctcatttgttctttatcgcatcttttgaaaacgctatcgaaatagcagtaccttcagactttttccgaatacagtttagccaaaaatatcaagaaaagcttgagcgcaagttcctcgaactttctggacaccccattaaacttttgtttgccgttaaaaaaggcacccctcatggaaatactgctccccccaaacacgtgcatacctacctggagaaaaactctcctgcagaggttccttccaaaaagagctttcaccccgacctgaacagagactataccttcgagaactttgtatccggagaagaaaccaaattcagccatagcgctgctatctccgtatcaaaaaacccaggcacttcctacaatccgttacttatctacggtggagtgggactaggaaaaacccaccttatgcaggctattggacacgagatctacaagacaacagacctgaacgtcatatacgtcactgcggagaattttggaaatgaattcatttccacattactcaataaaaagacccaggattttaaaaaaaaataccgctacaccgcggatgtacttcttatagatgacattcatttttttgaaaacaaagacggattacaagaagagcttttctatacgttcaacgaacttttcgagaaaaaaaaacaaattatctttacctgcgacaggcctgtacaagaattgaaaaatctctcttctcgcttacgctcgaggtgctcccgagggcttagcactgatctgaatatgccatgttttgaaacgcgctgtgctatcttgattaaaaaaatacaaaactataacagcacctatcctcacaaagccatccacatttcagacgatgttgtccgacttgtttctgaaaacatttcttcaaatatcagggatcttgagggggcattaacaaaaattatcgctttcattgaagtgtcgggatccatcacgatagatatcgttccctctctcctaaaagagttcttcctctctgcaaggccaaaacacatcacagtagaaactattcttcatgtagttgcagatcactttaacatttcgtattcagatctaaagggtaagaaacgcaataaaagcgttgtttatcctcggcaaatcgctatgtttctctcaaaggaactgacagagctctccactactgaacttggtatcgaatttggtggcagagatcattcaaccgtcatttacggatgtcaaaaaatagaaggagaaattctcactaatccttcgttacaggcaaatcttgatttgctgaaaagtaaagttcaagattcaatccgctag\n",
      "\t\tProtein :\tMDAVGYEVFWNETLSQIRSESTEAEFNMWFAHLFFIASFENAIEIAVPSDFFRIQFSQKYQEKLERKFLELSGHPIKLLFAVKKGTPHGNTAPPKHVHTYLEKNSPAEVPSKKSFHPDLNRDYTFENFVSGEETKFSHSAAISVSKNPGTSYNPLLIYGGVGLGKTHLMQAIGHEIYKTTDLNVIYVTAENFGNEFISTLLNKKTQDFKKKYRYTADVLLIDDIHFFENKDGLQEELFYTFNELFEKKKQIIFTCDRPVQELKNLSSRLRSRCSRGLSTDLNMPCFETRCAILIKKIQNYNSTYPHKAIHISDDVVRLVSENISSNIRDLEGALTKIIAFIEVSGSITIDIVPSLLKEFFLSARPKHITVETILHVVADHFNISYSDLKGKKRNKSVVYPRQIAMFLSKELTELSTTELGIEFGGRDHSTVIYGCQKIEGEILTNPSLQANLDLLKSKVQDSIR*\n",
      "\n",
      "\n",
      "gi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome:1640-2755, strand:1, id:TPASS_20002, name:dnaN\n",
      "Transcipts:\n",
      "\tgi_511533127_gb_CP004011_1_Treponema_pallidum_subsp_pallidum_SS14_complete_genome:1640-2755, strand: +, id:TPASS_20002, Protein, AA check\n",
      "\t\tExons:\n",
      "\n",
      "\n",
      "NEW VERSION!\n",
      "\tThere is a new SnpEff version available: \n",
      "\t\tVersion      : 4.4\n",
      "\t\tRelease date : 2019-01-26\n",
      "\t\tDownload URL : http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip\n",
      "\n",
      "(treponema) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Get the GenkBank full annotation - reference genome version and the gene annotation must be identical!\n",
    "#wget ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/bacteria/Treponema_pallidum/all_assembly_versions/GCA_000410555.1_ASM41055v1/GCA_000410555.1_ASM41055v1_genomic.gbff.gz -P $(dirname $REFERENCE)\n",
    "#gunzip $(dirname $REFERENCE)/GCA_000410555.1_ASM41055v1_genomic.gbff.gz\n",
    "cd $(dirname $REFERENCE)\n",
    "\n",
    "DB_NAME=\"SS14_CP004011.1\" # How you want to call the database?\n",
    "fasta_header=`head -1 $REFERENCE | sed 's/>//g' | cut -d ' ' -f 1` # Get only the fasta header without the initial \">\" and split after first empty space\n",
    "\n",
    "# Create custom snpEff.config\n",
    "echo \"$DB_NAME.genome : Treponema pallidum subsp. pallidum SS14\" > ${REFERENCE%.fa*}.snpEffect.config # Database name and description\n",
    "echo -e \"\\\\t$DB_NAME.chromosomes : $fasta_header\" >> ${REFERENCE%.fa*}.snpEffect.config # Database name and fasta header\n",
    "echo -e \"\\\\t$DB_NAME.$fasta_header.codonTable : Bacterial_and_Plant_Plastid\" >> ${REFERENCE%.fa*}.snpEffect.config # Database name, fasta header and codon table\n",
    "\n",
    "SNPEFF_DIR=$(ls -d $CONDA_PREFIX/share/snpeff-*/)\n",
    "echo $SNPEFF_DIR\n",
    "ANNOT_DIR=$SNPEFF_DIR/data/$DB_NAME # Data directory to store the added genome annotation\n",
    "\n",
    "# Make the annotation dabase - only once per genome!\n",
    "if [ ! -d \"$ANNOT_DIR\" ]; then  # Check if the genome folder already exists\n",
    "    mkdir -p $ANNOT_DIR\n",
    "    cd $ANNOT_DIR/\n",
    "\n",
    "    cat $(dirname $REFERENCE)/GCA_000410555.1_ASM41055v1_genomic.gbff > $ANNOT_DIR/genes.gbk\n",
    "\n",
    "    seq_name=`head -1 $ANNOT_DIR/genes.gbk | awk '{print $2}'` # Cheat a little and replace chromosome id with out sequence name - will work only with a single chromosome reference!!!\n",
    "    sed -i \"s/$seq_name/$fasta_header/g\" $ANNOT_DIR/genes.gbk\n",
    " \n",
    "    cat ${REFERENCE%.fa*}.snpEffect.config >> $SNPEFF_DIR/snpEff.config\n",
    "\n",
    "    cd $SNPEFF_DIR/\n",
    "    snpEff build -genbank -v $DB_NAME\n",
    "fi\n",
    "\n",
    "snpEff dump $DB_NAME | head -50 # Check if everything is OK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have the database ready we can run the variant effect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(treponema) (treponema) /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/variants/freebayes/CW56_S1_.SS14.filt.indelRealigned.dedup.MAPQ40.full.vcf\n",
      "\n",
      "\n",
      "NEW VERSION!\n",
      "\tThere is a new SnpEff version available: \n",
      "\t\tVersion      : 4.4\n",
      "\t\tRelease date : 2019-01-26\n",
      "\t\tDownload URL : http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip\n",
      "\n",
      "/mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/variants/freebayes/CW56_S1_.SS14.filt.indelRealigned.dedup.MAPQ40.var.vcf\n",
      "\n",
      "\n",
      "NEW VERSION!\n",
      "\tThere is a new SnpEff version available: \n",
      "\t\tVersion      : 4.4\n",
      "\t\tRelease date : 2019-01-26\n",
      "\t\tDownload URL : http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip\n",
      "\n",
      "(treponema) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd $SNPEFF_DIR/\n",
    "\n",
    "for sample in $OUTPUT_DIR/variants/freebayes/*.vcf\n",
    "do\n",
    "    echo $sample\n",
    "    snpEff $DB_NAME $sample > ${sample%.vcf}.$DB_NAME.annot.vcf\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### *De novo* assembly - mapped reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To accompany the alignment-guided assembly and to balance for the potentical pitfalls of that approach we strongly recommend to run *de novo* assembly as well. You can run *de novo* assembly on the host-cleaned data but since we assume there could be a mixture of organisms present we recommend to run the assembly only from the initial mapping step (\"rough mapping\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SAM/BAM to fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the preparation step, we first extract the mapped reads from the SAM/BAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir -p $OUTPUT_DIR/alignment/fastq\n",
    "\n",
    "cd $OUTPUT_DIR/alignment\n",
    "\n",
    "for sample in *.$(basename $REFERENCE .fa).bam\n",
    "do\n",
    "    echo \"Processing file $sample\"\n",
    "\n",
    "    samtools view -H $sample > ${sample%.*}.sam\n",
    "\n",
    "    samtools view -@ $THREADS -F 4 -f 3 $sample  >> ${sample%.*}.sam\n",
    "    samtools view -@ $THREADS -b ${sample%.*}.sam | samtools sort -@ $THREADS -o ${sample%.*}.mapped.bam -\n",
    "    rm ${sample%.*}.sam\n",
    "\n",
    "    picard FixMateInformation I=${sample%.*}.mapped.bam O=tmp.bam VALIDATION_STRINGENCY=LENIENT\n",
    "    mv tmp.bam ${sample%.*}.mapped.bam\n",
    "    samtools index -@ $THREADS ${sample%.*}.mapped.bam\n",
    "\n",
    "    samtools collate -O -@ $THREADS ${sample%.*}.mapped.bam - | samtools fastq -@ $THREADS -s $OUTPUT_DIR/alignment/fastq/${sample%.*}_unpaired.mapped.fastq -1 $OUTPUT_DIR/alignment/fastq/${sample%.*}_R1.mapped.fastq -2 $OUTPUT_DIR/alignment/fastq/${sample%.*}_R2.mapped.fastq -\n",
    "done\n",
    "\n",
    "cd $OUTPUT_DIR/alignment/fastq/\n",
    "\n",
    "rm *_unpaired.mapped.fastq\n",
    "\n",
    "for sample in *.fastq\n",
    "do\n",
    "    pigz -p $THREADS $sample\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### *De novo* assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can do the *de novo* assembly itself. In this section, we are using SPAdes but you can consider using [Unicycler](https://github.com/rrwick/Unicycler) or [metaSPADES](http://cab.spbu.ru/software/meta-spades/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "KMERS=\"15,21,27,33,55,77,99,127\" # List of kmers for the SPAdes assembly\n",
    "NSEQ=10 # How many longest sequences we will report in short assembly fasta result\n",
    "\n",
    "mkdir -p $OUTPUT_DIR/assembly/spades\n",
    "\n",
    "for sample in *R1.mapped.fastq.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "        echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "        echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "    \n",
    "    NAME=${FORWARD%R1*}\n",
    "\n",
    "    mkdir $OUTPUT_DIR/assembly/spades/$NAME\n",
    "\n",
    "    spades.py --careful --threads $THREADS --cov-cutoff 5 --tmp-dir $OUTPUT_DIR/tmp -k $KMERS -1 $FORWARD -2 $REVERSE -o $OUTPUT_DIR/assembly/spades/$NAME\n",
    "done\n",
    "\n",
    "# Assembly statistics\n",
    "cd $OUTPUT_DIR/assembly/spades\n",
    "\n",
    "dirs_tmp=$(ls -d */)\n",
    "\n",
    "mkdir scaffolds\n",
    "mkdir graphs\n",
    "\n",
    "for sample in $dirs_tmp\n",
    "do\n",
    "    cat $sample/scaffolds.fasta > scaffolds/${sample%/*}.scaffolds.fasta\n",
    "    cat $sample/assembly_graph.fastg > graphs/${sample%/*}.assembly_graph.fastg\n",
    "    cat $sample/assembly_graph_with_scaffolds.gfa > graphs/${sample%/*}.assembly_graph_with_scaffolds.gfa\n",
    "done\n",
    "\n",
    "cd scaffolds/\n",
    "\n",
    "for sample in *.fasta\n",
    "do\n",
    "    awk \"/^>/ {n++} n>$NSEQ {exit} {print}\" $sample > ${sample%.*}.top${NSEQ}.fasta\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Assembly quality check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once the assembly is done we strongly recommend to run assembly quality check. We also recommend looking at the resulting graphs at [Bandage](https://rrwick.github.io/Bandage/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir -p $OUTPUT_DIR/qc/assembly/BUSCO\n",
    "mkdir $OUTPUT_DIR/qc/assembly/quast\n",
    "\n",
    "#BUSCO_INI=/storage/brno2/home/opplatek/tools/anaconda3/envs/busco/share/busco-3.0.2-6/conda.config.ini\n",
    "#export BUSCO_CONFIG_FILE=$SCRATCH/busco.ini\n",
    "\n",
    "# Get BUSCO core genes annotation database\n",
    "wget https://busco.ezlab.org/datasets/spirochaetes_odb9.tar.gz -O $OUTPUT_DIR/qc/assembly/BUSCO/spirochaetes_odb9.tar.gz\n",
    "tar xvzf $OUTPUT_DIR/qc/assembly/BUSCO/spirochaetes_odb9.tar.gz -C $OUTPUT_DIR/qc/assembly/BUSCO\n",
    "\n",
    "#cp -r /storage/brno2/home/opplatek/tools/anaconda3/pkgs/augustus-3.2.3-boost1.60_0/config $SCRATCH/augustus_config\n",
    "#export AUGUSTUS_CONFIG_PATH=$SCRATCH/augustus_config\n",
    "\n",
    "# -sp XXX is one of the supported organisms by Augustus and should be as close as possible to our organism https://github.com/Gaius-Augustus/Augustus/blob/master/docs/RUNNING-AUGUSTUS.md\n",
    "\n",
    "for sample in *.scaffolds.fasta\n",
    "do\n",
    "    mkdir $OUTPUT_DIR/qc/assembly/BUSCO/${sample%.fa*}\n",
    "    \n",
    "    run_BUSCO.py -i $sample -o busco_${sample%.fa*} -l $OUTPUT_DIR/qc/assembly/BUSCO/spirochaetes_odb9 -m geno \\\n",
    "    -c $THREADS -sp E_coli_K12 -t $OUTPUT_DIR/tmp\n",
    "done\n",
    "\n",
    "mv run_busco* $OUTPUT_DIR/qc/assembly/BUSCO/\n",
    "\n",
    "quast -r $REFERENCE -t $THREADS --output-dir $OUTPUT_DIR/qc/assembly/quast *.scaffolds.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Additional scaffolding (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "SPAdes is quite efficient in the scaffolding and we never had a need to do additional scaffolding but you might find yourself in a situation to do so. We are using [BESST](https://github.com/ksahlin/BESST) but there are other options such as [SSPACE-basic] (https://github.com/nsoranzo/sspace_basic), [SSPACE-standard](https://www.baseclear.com/services/bioinformatics/basetools/sspace-standard/) and others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **extremely** important to compare the original assembly scaffolds and the \"re-scaffolded\" ones and determine which ones we want to use. Longer doesn't always mean better. Carefully check the Quast report and compare the original vs. re-scaffolded and make the decision. I would always check \"# misassemblies\" and consider if it has improved or not or if there is some biology behind the change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the best functionality, you have know the insert size. You can get this information from the Qualimap report which we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/assembly/spades/scaffolds_besst: File exists\n",
      "(treponema) (treponema) (treponema) (treponema) [bwa_index] Pack FASTA... 0.01 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.30 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.01 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.01 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.12 sec\n",
      "[main] Version: 0.7.15-r1140\n",
      "[main] CMD: bwa index /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/assembly/spades/scaffolds/CW56_S1_.SS14_.scaffolds.fasta\n",
      "[main] Real time: 0.452 sec; CPU: 0.448 sec\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 837234 sequences (120000108 bp)...\n",
      "[M::process] read 837314 sequences (120000224 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 414208, 1, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (166, 235, 334)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 670)\n",
      "[M::mem_pestat] mean and std.dev: (258.05, 127.45)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 838)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 837234 reads in 62.796 CPU sec, 6.410 real sec\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (3, 414131, 1, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (166, 234, 334)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 670)\n",
      "[M::mem_pestat] mean and std.dev: (257.79, 127.47)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 838)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 837314 reads in 51.116 CPU sec, 5.077 real sec\n",
      "[M::process] read 837302 sequences (120000281 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (6, 414094, 1, 1)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (166, 234, 334)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 670)\n",
      "[M::mem_pestat] mean and std.dev: (257.78, 127.56)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 838)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 837302 reads in 46.964 CPU sec, 4.083 real sec\n",
      "[M::process] read 837256 sequences (120000258 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (2, 414151, 0, 3)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (166, 234, 334)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 670)\n",
      "[M::mem_pestat] mean and std.dev: (257.80, 127.42)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 838)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 837256 reads in 45.880 CPU sec, 4.031 real sec\n",
      "[M::process] read 611512 sequences (87644109 bp)...\n",
      "[M::mem_pestat] # candidate unique pairs for (FF, FR, RF, RR): (5, 302510, 1, 0)\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (166, 234, 333)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 667)\n",
      "[M::mem_pestat] mean and std.dev: (257.65, 127.48)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 834)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_process_seqs] Processed 611512 reads in 32.412 CPU sec, 2.828 real sec\n",
      "[main] Version: 0.7.15-r1140\n",
      "[main] CMD: bwa mem -t 12 -w 0 -O 99 /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/assembly/spades/scaffolds/CW56_S1_.SS14_.scaffolds.fasta CW56_S1_.SS14_R1.mapped.fastq.gz CW56_S1_.SS14_R2.mapped.fastq.gz\n",
      "[main] Real time: 83.598 sec; CPU: 256.536 sec\n",
      "Number of initial contigs: 67\n",
      "Choosing mode: 202\n",
      "mu_adjusted:267.683802437, sigma_adjusted:141.107994789, skewness_adjusted:1.12571613121\n",
      "mode adj: 202\n",
      "median adj 238\n",
      "Creating contig graph with library:  /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/assembly/spades/scaffolds_besst/CW56_S1_.SS14_.mapped.bam\n",
      "Constructed contig graph. Start BESST algorithm for creating scaffolds. \n",
      "Entering \"find_all_paths_for_start_node\" \n",
      "iterating until maximum of 14 extensions.\n",
      "Number of nodes:134, Number of edges: 89\n",
      "enter Between scaf node:0, scaffold progression 0.0%. \n",
      "Total nr of paths found: 2 with score larger than: 1.5\n",
      "Elapsed time single core pathfinder:  0.000922203063965\n",
      "Writing out scaffolding results for step 1  ...\n",
      "Finished\n",
      "\n",
      " \n",
      "(treponema) "
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "mkdir $OUTPUT_DIR/assembly/spades/scaffolds_besst\n",
    "mkdir $OUTPUT_DIR/qc/assembly/quast_besst\n",
    "\n",
    "cd $OUTPUT_DIR/alignment/fastq\n",
    "\n",
    "for sample in *R1.mapped.fastq.gz\n",
    "do\n",
    "    FORWARD=$sample\n",
    "    extension=\"${FORWARD##*R1}\"\n",
    "    REVERSE=${FORWARD%R1*}R2${extension}\n",
    "\n",
    "    # Input file check\n",
    "    if [ ! -f ${FORWARD} ]; then\n",
    "        echo \"Input file not found! First in pair.\"; echo ${FORWARD}\n",
    "    fi\n",
    "    if [ ! -f ${REVERSE} ]; then\n",
    "        echo \"Input file not found! Second in pair.\"; echo ${REVERSE}\n",
    "    fi\n",
    "    \n",
    "    contig=$OUTPUT_DIR/assembly/spades/scaffolds/${FORWARD%R1*}.scaffolds.fasta # SPAdes assembly contigs/scaffolds\n",
    "\n",
    "    bwa index $contig\n",
    "\n",
    "    bwa mem -t $THREADS -w 0 -O 99 $contig $FORWARD $REVERSE | samtools view -F 4 -@ $THREADS -b - | samtools fixmate -O bam - - | samtools sort -@ $THREADS - > $OUTPUT_DIR/assembly/spades/scaffolds_besst/${FORWARD%R1*}${extension%.fastq.gz*}.bam # Make alignment for BESST; default is BWA-MEM and recommended settings are used; they have script to do it (reads_to_ctg_map.py) but it has some error - setting taken from there\n",
    "\n",
    "    samtools index -@ $THREADS $OUTPUT_DIR/assembly/spades/scaffolds_besst/${FORWARD%R1*}${extension%.fastq.gz*}.bam\n",
    "\n",
    "    mkdir $OUTPUT_DIR/assembly/spades/scaffolds_besst/${FORWARD%R1*}\n",
    "\n",
    "#  -m MEAN [MEAN ...]    Mean insert size of libraries.\n",
    "#  -s STDDEV [STDDEV ...]\n",
    "#                        Estimated standard deviation of libraries.\n",
    "    runBESST -c $contig -f $OUTPUT_DIR/assembly/spades/scaffolds_besst/${FORWARD%R1*}${extension%.fastq.gz*}.bam -filter_contigs 100 -orientation fr -o $OUTPUT_DIR/assembly/spades/scaffolds_besst/${FORWARD%R1*}\n",
    "done\n",
    "\n",
    "rm $OUTPUT_DIR/assembly/spades/scaffolds_besst/*.bam*\n",
    "\n",
    "cd $OUTPUT_DIR/assembly/spades/scaffolds_besst\n",
    "\n",
    "for sample in $(ls -d */)\n",
    "do\n",
    "    cat $sample/BESST_output/pass1/Scaffolds_pass1.fa > $OUTPUT_DIR/assembly/spades/scaffolds_besst/${sample%/*}.scaffolds.fasta\n",
    "done\n",
    "\n",
    "cd $OUTPUT_DIR/assembly/spades/scaffolds_besst/\n",
    "\n",
    "for sample in *.scaffolds.fasta\n",
    "do\n",
    "    cat $sample | awk '/^>/ {printf(\"%s%s\\t\",(N>0?\"\\n\":\"\"),$0);N++;next;} {printf(\"%s\",$0);} END {printf(\"\\n\");}' | awk -F '\\t' '{printf(\"%d\\t%s\\n\",length($2),$0);}' | sort -k1,1nr | cut -f 2- | tr \"\\t\" \"\\n\" > $sample.tmp # Longest first; shortest first change sort 'sort -k1,1nr' to 'sort -k1,1n'\n",
    "    mv $sample.tmp $sample\n",
    "    cat $sample > $OUTPUT_DIR/assembly/spades/scaffolds/${sample%.scaffolds.fasta}.scaffolds_besst.fasta \n",
    "done\n",
    "\n",
    "cd $OUTPUT_DIR/assembly/spades/scaffolds\n",
    "\n",
    "quast -r $REFERENCE -t $THREADS --output-dir $OUTPUT_DIR/qc/assembly/quast *.scaffolds*.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Scaffold contamination scan (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have the assembly checked, ready and potentialy extended using the additional scaffolding we can run the \"contamination\" scan once more. This time not on the sequencing reads themselves but on the resulting scaffolds. We will be using Kraken2 again but be aware that Kraken2 evaluates the percentages (the first column) based on the number of reads assigned to the individual phylogenetic groups. Since we now have scaffolds of different lengths the statistics might be misleading. It's better to keep only longer scaffolds to avoid counting unscaffolded short sequences which might be heavily over abundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory /mnt/ssd/ssd_2/bioda_temp/honza/scratch_default/linda/results/qc/kraken2/scaffolds: File exists\n",
      "(treponema) (treponema) java -ea -Xmx200m -cp /mnt/nfs/home/323639/000000-My_Documents/VM-home/tools/miniconda2/envs/treponema/opt/bbmap-38.22-1/current/ jgi.ReformatReads in=CW56_S1_.SS14_.scaffolds.fasta out=CW56_S1_.SS14_.scaffolds.fasta.tmp.fasta minlength=1000\n",
      "Executing jgi.ReformatReads [in=CW56_S1_.SS14_.scaffolds.fasta, out=CW56_S1_.SS14_.scaffolds.fasta.tmp.fasta, minlength=1000]\n",
      "\n",
      "Input is being processed as unpaired\n",
      "Input:                  \t67 reads          \t1153760 bases\n",
      "Short Read Discards:    \t48 reads (71.64%) \t20126 bases (1.74%)\n",
      "Output:                 \t19 reads (28.36%) \t1133634 bases (98.26%)\n",
      "\n",
      "Time:                         \t0.381 seconds.\n",
      "Reads Processed:          67 \t0.18k reads/sec\n",
      "Bases Processed:       1153k \t3.03m bases/sec\n"
     ]
    }
   ],
   "source": [
    "mkdir $OUTPUT_DIR/qc/kraken2/scaffolds\n",
    "\n",
    "for sample in *.scaffolds.fasta\n",
    "do\n",
    "    reformat.sh in=$sample out=$sample.tmp.fasta minlength=1000 # Get only scaffolds >=1000 bp\n",
    "\n",
    "    kraken2 --threads $THREADS --use-names --classified-out $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.classified-out.fasta --unclassified-out $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.unclassified-out.fasta --output $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.kraken.txt --report $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.kraken.report.txt --db $KRAKEN2_DB $sample.tmp.fasta\n",
    "    rm $sample.tmp.fasta\n",
    "\n",
    "    # Extract only the annotated reads and their taxa\n",
    "    cat $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.kraken.txt | cut -f2,3 > $OUTPUT_DIR/qc/kraken2/scaffolds/${sample%.scaffolds.fasta}.kraken.taxid.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Gene prediction (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we are sure out assembly is correct, clean and we want to proceed to further analysis we can try gene prediction on the scaffolded assembly. We use [PROKKA](https://github.com/tseemann/prokka) but there are other options as well such as [RAST](http://rast.nmpdr.org/), [Augustus](http://bioinf.uni-greifswald.de/webaugustus/index.gsp), [funannotate](https://github.com/nextgenusfs/funannotate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# If we have a set of HIGHLY trusted proteins we can add the in genebank (gbk) format and assign GBK variable pointing to the file\n",
    "#GBK=/path/to/species_trusted_proteins.gbk\n",
    "\n",
    "for sample in *.scaffolds.fasta\n",
    "do\n",
    "    prokka --cpus $THREADS --kingdom Bacteria --outdir $OUTPUT_DIR/assembly/gene_prediction --prefix ${sample%.fa*} $sample # --proteins $GBK\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At this point, there is bug in PROKKA-minced conda installation. If you get an error with `Error: A JNI error has occurred, please check your installation and try again\n",
    "Exception in thread \"main\" java.lang.UnsupportedClassVersionError: minced has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0...` you have to downgrade minced to version 0.3.3 (or rebuild from souce). Most likely right now it's at version 0.4.0 and Java at version 1.8.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Results in error\n",
    "minced --version\n",
    "# Check minced version\n",
    "ls -l $CONDA_PREFIX/bin/minced\n",
    "# Check java version\n",
    "java -version\n",
    "# Download minced-0.3.0\n",
    "mkdir $CONDA_PREFIX/share/minced-0.3.3\n",
    "wget https://github.com/ctSkennerton/minced/releases/download/0.3.3/minced.jar -O $CONDA_PREFIX/share/minced-0.3.3/minced.jar\n",
    "wget https://github.com/ctSkennerton/minced/releases/download/0.3.3/minced -O $CONDA_PREFIX/share/minced-0.3.3/minced\n",
    "chmod u+x $CONDA_PREFIX/share/minced-0.3.3/minced\n",
    "export PATH=$CONDA_PREFIX/share/minced-0.3.3:$PATH\n",
    "# Should work fine\n",
    "which minced\n",
    "minced --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And now you can rerun the gene prediction (PROKKA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Whole genome alignment (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Another thing we can do with the assembly is to look at the whole-genome similarities and try to fix the orientation of the resulting scaffolds. This can be done using whole-genome alignment of the scaffolds and the related reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir $OUTPUT_DIR/assembly/genome_alignment\n",
    "\n",
    "for sample in *.scaffolds.fasta\n",
    "do\n",
    "    sample_name=$(basename $sample .fasta)\n",
    "\n",
    "    mkdir $OUTPUT_DIR/assembly/genome_alignment/$sample_name\n",
    "\n",
    "    nucmer -p $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer $REFERENCE $sample\n",
    "\n",
    "    dnadiff -p $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer -d $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.delta\n",
    "\n",
    "    mummerplot -p $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer -s large --SNP --postscript --filter $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.delta\n",
    "    mummerplot -p $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer -s large --SNP --png --filter $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.delta\n",
    "\n",
    "    mkdir $OUTPUT_DIR/assembly/genome_alignment/$sample_name/individual_alignments\n",
    "\n",
    "    grep \">\" $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.delta | cut -d ' ' -f1,2 | sed 's/>//g' | while read list\n",
    "    do\n",
    "        echo $list\n",
    "        outname=`echo $list | sed 's/ /_/g'`\n",
    "        \n",
    "        show-aligns $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.delta $list > $OUTPUT_DIR/assembly/genome_alignment/$sample_name/individual_alignments/$outname.aln\n",
    "    done\n",
    "\n",
    "    # Extract unaligned scaffolds to the reference\n",
    "    cat $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.unqry | cut -f1 > $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.unqry.names\n",
    "    seqtk subseq $sample $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.unqry.names > $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.unqry.fasta\n",
    "    rm $OUTPUT_DIR/assembly/genome_alignment/$sample_name/nucmer.unqry.names\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
